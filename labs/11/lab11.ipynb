{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11 - Logistic Regression\n",
    "## Lecture 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = iris[,c('Species','Sepal.Length','Sepal.Width')]\n",
    "dset = dset[dset$Species %in% c(\"virginica\",\"versicolor\"),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    setosa versicolor  virginica \n",
       "         0         50         50 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(dset$Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "versicolor  virginica \n",
       "        50         50 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "levels(dset$Species) = c(NA,\"versicolor\",\"virginica\")\n",
    "dset$Species = relevel(dset$Species,ref=\"versicolor\")\n",
    "table(dset$Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li></ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<style>\n",
       "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
       "\t.list-inline>li {display: inline-block}\n",
       "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "\t</style>\n",
       "\t<ol class=list-inline><li>'versicolor'</li><li>'virginica'</li></ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'versicolor'\n",
       "\\item 'virginica'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. versicolor\n",
       "2. versicolor\n",
       "3. versicolor\n",
       "4. versicolor\n",
       "5. versicolor\n",
       "6. versicolor\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'versicolor'\n",
       "2. 'virginica'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] versicolor versicolor versicolor versicolor versicolor versicolor\n",
       "Levels: versicolor virginica"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li><li>1</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 1\n",
       "3. 1\n",
       "4. 1\n",
       "5. 1\n",
       "6. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1 1 1 1 1 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(dset$Species)\n",
    "head(as.numeric(dset$Species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for glm {stats}\"><tr><td>glm {stats}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Fitting Generalized Linear Models</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p><code>glm</code> is used to fit generalized linear models, specified by\n",
       "giving a symbolic description of the linear predictor and a\n",
       "description of the error distribution.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "glm(formula, family = gaussian, data, weights, subset,\n",
       "    na.action, start = NULL, etastart, mustart, offset,\n",
       "    control = list(...), model = TRUE, method = \"glm.fit\",\n",
       "    x = FALSE, y = TRUE, singular.ok = TRUE, contrasts = NULL, ...)\n",
       "\n",
       "glm.fit(x, y, weights = rep.int(1, nobs),\n",
       "        start = NULL, etastart = NULL, mustart = NULL,\n",
       "        offset = rep.int(0, nobs), family = gaussian(),\n",
       "        control = list(), intercept = TRUE, singular.ok = TRUE)\n",
       "\n",
       "## S3 method for class 'glm'\n",
       "weights(object, type = c(\"prior\", \"working\"), ...)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>formula</code></td>\n",
       "<td>\n",
       "<p>an object of class <code>\"formula\"</code> (or one that\n",
       "can be coerced to that class): a symbolic description of the\n",
       "model to be fitted.  The details of model specification are given\n",
       "under &lsquo;Details&rsquo;.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>family</code></td>\n",
       "<td>\n",
       "<p>a description of the error distribution and link\n",
       "function to be used in the model.  For <code>glm</code> this can be a\n",
       "character string naming a family function, a family function or the\n",
       "result of a call to a family function.  For <code>glm.fit</code> only the\n",
       "third option is supported.  (See <code>family</code> for details of\n",
       "family functions.)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>data</code></td>\n",
       "<td>\n",
       "<p>an optional data frame, list or environment (or object\n",
       "coercible by <code>as.data.frame</code> to a data frame) containing\n",
       "the variables in the model.  If not found in <code>data</code>, the\n",
       "variables are taken from <code>environment(formula)</code>,\n",
       "typically the environment from which <code>glm</code> is called.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>weights</code></td>\n",
       "<td>\n",
       "<p>an optional vector of &lsquo;prior weights&rsquo; to be used\n",
       "in the fitting process.  Should be <code>NULL</code> or a numeric vector.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>subset</code></td>\n",
       "<td>\n",
       "<p>an optional vector specifying a subset of observations\n",
       "to be used in the fitting process.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>na.action</code></td>\n",
       "<td>\n",
       "<p>a function which indicates what should happen\n",
       "when the data contain <code>NA</code>s.  The default is set by\n",
       "the <code>na.action</code> setting of <code>options</code>, and is\n",
       "<code>na.fail</code> if that is unset.  The &lsquo;factory-fresh&rsquo;\n",
       "default is <code>na.omit</code>.  Another possible value is\n",
       "<code>NULL</code>, no action.  Value <code>na.exclude</code> can be useful.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>start</code></td>\n",
       "<td>\n",
       "<p>starting values for the parameters in the linear predictor.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>etastart</code></td>\n",
       "<td>\n",
       "<p>starting values for the linear predictor.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>mustart</code></td>\n",
       "<td>\n",
       "<p>starting values for the vector of means.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>offset</code></td>\n",
       "<td>\n",
       "<p>this can be used to specify an <em>a priori</em> known\n",
       "component to be included in the linear predictor during fitting.\n",
       "This should be <code>NULL</code> or a numeric vector of length equal to\n",
       "the number of cases.  One or more <code>offset</code> terms can be\n",
       "included in the formula instead or as well, and if more than one is\n",
       "specified their sum is used.  See <code>model.offset</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>control</code></td>\n",
       "<td>\n",
       "<p>a list of parameters for controlling the fitting\n",
       "process.  For <code>glm.fit</code> this is passed to\n",
       "<code>glm.control</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>model</code></td>\n",
       "<td>\n",
       "<p>a logical value indicating whether <em>model frame</em>\n",
       "should be included as a component of the returned value.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>method</code></td>\n",
       "<td>\n",
       "<p>the method to be used in fitting the model.  The default\n",
       "method <code>\"glm.fit\"</code> uses iteratively reweighted least squares\n",
       "(IWLS): the alternative <code>\"model.frame\"</code> returns the model frame\n",
       "and does no fitting.\n",
       "</p>\n",
       "<p>User-supplied fitting functions can be supplied either as a function\n",
       "or a character string naming a function, with a function which takes\n",
       "the same arguments as <code>glm.fit</code>.  If specified as a character\n",
       "string it is looked up from within the <span class=\"pkg\">stats</span> namespace.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>x, y</code></td>\n",
       "<td>\n",
       "<p>For <code>glm</code>:\n",
       "logical values indicating whether the response vector and model\n",
       "matrix used in the fitting process should be returned as components\n",
       "of the returned value.\n",
       "</p>\n",
       "<p>For <code>glm.fit</code>: <code>x</code> is a design matrix of dimension\n",
       "<code>n * p</code>, and <code>y</code> is a vector of observations of length\n",
       "<code>n</code>.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>singular.ok</code></td>\n",
       "<td>\n",
       "<p>logical; if <code>FALSE</code> a singular fit is an\n",
       "error.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>contrasts</code></td>\n",
       "<td>\n",
       "<p>an optional list. See the <code>contrasts.arg</code>\n",
       "of <code>model.matrix.default</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>intercept</code></td>\n",
       "<td>\n",
       "<p>logical. Should an intercept be included in the\n",
       "<em>null</em> model?</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>object</code></td>\n",
       "<td>\n",
       "<p>an object inheriting from class <code>\"glm\"</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>type</code></td>\n",
       "<td>\n",
       "<p>character, partial matching allowed.  Type of weights to\n",
       "extract from the fitted model object.  Can be abbreviated.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "\n",
       "<p>For <code>glm</code>: arguments to be used to form the default\n",
       "<code>control</code> argument if it is not supplied directly.\n",
       "</p>\n",
       "<p>For <code>weights</code>: further arguments passed to or from other methods.\n",
       "</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>A typical predictor has the form <code>response ~ terms</code> where\n",
       "<code>response</code> is the (numeric) response vector and <code>terms</code> is a\n",
       "series of terms which specifies a linear predictor for\n",
       "<code>response</code>.  For <code>binomial</code> and <code>quasibinomial</code>\n",
       "families the response can also be specified as a <code>factor</code>\n",
       "(when the first level denotes failure and all others success) or as a\n",
       "two-column matrix with the columns giving the numbers of successes and\n",
       "failures.  A terms specification of the form <code>first + second</code>\n",
       "indicates all the terms in <code>first</code> together with all the terms in\n",
       "<code>second</code> with any duplicates removed.\n",
       "</p>\n",
       "<p>A specification of the form <code>first:second</code> indicates the set\n",
       "of terms obtained by taking the interactions of all terms in\n",
       "<code>first</code> with all terms in <code>second</code>.  The specification\n",
       "<code>first*second</code> indicates the <em>cross</em> of <code>first</code> and\n",
       "<code>second</code>.  This is the same as <code>first + second +\n",
       "  first:second</code>.\n",
       "</p>\n",
       "<p>The terms in the formula will be re-ordered so that main effects come\n",
       "first, followed by the interactions, all second-order, all third-order\n",
       "and so on: to avoid this pass a <code>terms</code> object as the formula.\n",
       "</p>\n",
       "<p>Non-<code>NULL</code> <code>weights</code> can be used to indicate that different\n",
       "observations have different dispersions (with the values in\n",
       "<code>weights</code> being inversely proportional to the dispersions); or\n",
       "equivalently, when the elements of <code>weights</code> are positive\n",
       "integers <i>w_i</i>, that each response <i>y_i</i> is the mean of\n",
       "<i>w_i</i> unit-weight observations.  For a binomial GLM prior weights\n",
       "are used to give the number of trials when the response is the\n",
       "proportion of successes: they would rarely be used for a Poisson GLM.\n",
       "</p>\n",
       "<p><code>glm.fit</code> is the workhorse function: it is not normally called\n",
       "directly but can be more efficient where the response vector, design\n",
       "matrix and family have already been calculated.\n",
       "</p>\n",
       "<p>If more than one of <code>etastart</code>, <code>start</code> and <code>mustart</code>\n",
       "is specified, the first in the list will be used.  It is often\n",
       "advisable to supply starting values for a <code>quasi</code> family,\n",
       "and also for families with unusual links such as <code>gaussian(\"log\")</code>.\n",
       "</p>\n",
       "<p>All of <code>weights</code>, <code>subset</code>, <code>offset</code>, <code>etastart</code>\n",
       "and <code>mustart</code> are evaluated in the same way as variables in\n",
       "<code>formula</code>, that is first in <code>data</code> and then in the\n",
       "environment of <code>formula</code>.\n",
       "</p>\n",
       "<p>For the background to warning messages about &lsquo;fitted probabilities\n",
       "numerically 0 or 1 occurred&rsquo; for binomial GLMs, see Venables &amp;\n",
       "Ripley (2002, pp. 197&ndash;8).\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p><code>glm</code> returns an object of class inheriting from <code>\"glm\"</code>\n",
       "which inherits from the class <code>\"lm\"</code>. See later in this section.\n",
       "If a non-standard <code>method</code> is used, the object will also inherit\n",
       "from the class (if any) returned by that function.\n",
       "</p>\n",
       "<p>The function <code>summary</code> (i.e., <code>summary.glm</code>) can\n",
       "be used to obtain or print a summary of the results and the function\n",
       "<code>anova</code> (i.e., <code>anova.glm</code>)\n",
       "to produce an analysis of variance table.\n",
       "</p>\n",
       "<p>The generic accessor functions <code>coefficients</code>,\n",
       "<code>effects</code>, <code>fitted.values</code> and <code>residuals</code> can be used to\n",
       "extract various useful features of the value returned by <code>glm</code>.\n",
       "</p>\n",
       "<p><code>weights</code> extracts a vector of weights, one for each case in the\n",
       "fit (after subsetting and <code>na.action</code>).\n",
       "</p>\n",
       "<p>An object of class <code>\"glm\"</code> is a list containing at least the\n",
       "following components:\n",
       "</p>\n",
       "<table summary=\"R valueblock\">\n",
       "<tr valign=\"top\"><td><code>coefficients</code></td>\n",
       "<td>\n",
       "<p>a named vector of coefficients</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>residuals</code></td>\n",
       "<td>\n",
       "<p>the <em>working</em> residuals, that is the residuals\n",
       "in the final iteration of the IWLS fit.  Since cases with zero\n",
       "weights are omitted, their working residuals are <code>NA</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>fitted.values</code></td>\n",
       "<td>\n",
       "<p>the fitted mean values, obtained by transforming\n",
       "the linear predictors by the inverse of the link function.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>rank</code></td>\n",
       "<td>\n",
       "<p>the numeric rank of the fitted linear model.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>family</code></td>\n",
       "<td>\n",
       "<p>the <code>family</code> object used.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>linear.predictors</code></td>\n",
       "<td>\n",
       "<p>the linear fit on link scale.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>deviance</code></td>\n",
       "<td>\n",
       "<p>up to a constant, minus twice the maximized\n",
       "log-likelihood.  Where sensible, the constant is chosen so that a\n",
       "saturated model has deviance zero.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>aic</code></td>\n",
       "<td>\n",
       "<p>A version of Akaike's <em>An Information Criterion</em>,\n",
       "minus twice the maximized log-likelihood plus twice the number of\n",
       "parameters, computed via the <code>aic</code> component of the family.\n",
       "For binomial and Poison families the dispersion is\n",
       "fixed at one and the number of parameters is the number of\n",
       "coefficients.  For gaussian, Gamma and inverse gaussian families the\n",
       "dispersion is estimated from the residual deviance, and the number\n",
       "of parameters is the number of coefficients plus one.  For a\n",
       "gaussian family the MLE of the dispersion is used so this is a valid\n",
       "value of AIC, but for Gamma and inverse gaussian families it is not.\n",
       "For families fitted by quasi-likelihood the value is <code>NA</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>null.deviance</code></td>\n",
       "<td>\n",
       "<p>The deviance for the null model, comparable with\n",
       "<code>deviance</code>. The null model will include the offset, and an\n",
       "intercept if there is one in the model.  Note that this will be\n",
       "incorrect if the link function depends on the data other than\n",
       "through the fitted mean: specify a zero offset to force a correct\n",
       "calculation.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>iter</code></td>\n",
       "<td>\n",
       "<p>the number of iterations of IWLS used.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>weights</code></td>\n",
       "<td>\n",
       "<p>the <em>working</em> weights, that is the weights\n",
       "in the final iteration of the IWLS fit.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>prior.weights</code></td>\n",
       "<td>\n",
       "<p>the weights initially supplied, a vector of\n",
       "<code>1</code>s if none were.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>df.residual</code></td>\n",
       "<td>\n",
       "<p>the residual degrees of freedom.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>df.null</code></td>\n",
       "<td>\n",
       "<p>the residual degrees of freedom for the null model.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>y</code></td>\n",
       "<td>\n",
       "<p>if requested (the default) the <code>y</code> vector\n",
       "used. (It is a vector even for a binomial model.)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>x</code></td>\n",
       "<td>\n",
       "<p>if requested, the model matrix.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>model</code></td>\n",
       "<td>\n",
       "<p>if requested (the default), the model frame.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>converged</code></td>\n",
       "<td>\n",
       "<p>logical. Was the IWLS algorithm judged to have converged?</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>boundary</code></td>\n",
       "<td>\n",
       "<p>logical. Is the fitted value on the boundary of the\n",
       "attainable values?</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>call</code></td>\n",
       "<td>\n",
       "<p>the matched call.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>formula</code></td>\n",
       "<td>\n",
       "<p>the formula supplied.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>terms</code></td>\n",
       "<td>\n",
       "<p>the <code>terms</code> object used.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>data</code></td>\n",
       "<td>\n",
       "<p>the <code>data argument</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>offset</code></td>\n",
       "<td>\n",
       "<p>the offset vector used.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>control</code></td>\n",
       "<td>\n",
       "<p>the value of the <code>control</code> argument used.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>method</code></td>\n",
       "<td>\n",
       "<p>the name of the fitter function used (when provided as a\n",
       "<code>character</code> string to <code>glm()</code>) or the fitter\n",
       "<code>function</code> (when provided as that).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>contrasts</code></td>\n",
       "<td>\n",
       "<p>(where relevant) the contrasts used.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>xlevels</code></td>\n",
       "<td>\n",
       "<p>(where relevant) a record of the levels of the factors\n",
       "used in fitting.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>na.action</code></td>\n",
       "<td>\n",
       "<p>(where relevant) information returned by\n",
       "<code>model.frame</code> on the special handling of <code>NA</code>s.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "<p>In addition, non-empty fits will have components <code>qr</code>, <code>R</code>\n",
       "and <code>effects</code> relating to the final weighted linear fit.\n",
       "</p>\n",
       "<p>Objects of class <code>\"glm\"</code> are normally of class <code>c(\"glm\",\n",
       "    \"lm\")</code>, that is inherit from class <code>\"lm\"</code>, and well-designed\n",
       "methods for class <code>\"lm\"</code> will be applied to the weighted linear\n",
       "model at the final iteration of IWLS.  However, care is needed, as\n",
       "extractor functions for class <code>\"glm\"</code> such as\n",
       "<code>residuals</code> and <code>weights</code> do <b>not</b> just pick out\n",
       "the component of the fit with the same name.\n",
       "</p>\n",
       "<p>If a <code>binomial</code> <code>glm</code> model was specified by giving a\n",
       "two-column response, the weights returned by <code>prior.weights</code> are\n",
       "the total numbers of cases (factored by the supplied case weights) and\n",
       "the component <code>y</code> of the result is the proportion of successes.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Fitting functions</h3>\n",
       "\n",
       "<p>The argument <code>method</code> serves two purposes.  One is to allow the\n",
       "model frame to be recreated with no fitting.  The other is to allow\n",
       "the default fitting function <code>glm.fit</code> to be replaced by a\n",
       "function which takes the same arguments and uses a different fitting\n",
       "algorithm.  If <code>glm.fit</code> is supplied as a character string it is\n",
       "used to search for a function of that name, starting in the\n",
       "<span class=\"pkg\">stats</span> namespace.\n",
       "</p>\n",
       "<p>The class of the object return by the fitter (if any) will be\n",
       "prepended to the class returned by <code>glm</code>.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "<p>The original <span style=\"font-family: Courier New, Courier; color: #666666;\"><b>R</b></span> implementation of <code>glm</code> was written by Simon\n",
       "Davies working for Ross Ihaka at the University of Auckland, but has\n",
       "since been extensively re-written by members of the R Core team.\n",
       "</p>\n",
       "<p>The design was inspired by the S function of the same name described\n",
       "in Hastie &amp; Pregibon (1992).\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "<p>Dobson, A. J. (1990)\n",
       "<em>An Introduction to Generalized Linear Models.</em>\n",
       "London: Chapman and Hall.\n",
       "</p>\n",
       "<p>Hastie, T. J. and Pregibon, D. (1992)\n",
       "<em>Generalized linear models.</em>\n",
       "Chapter 6 of <em>Statistical Models in S</em>\n",
       "eds J. M. Chambers and T. J. Hastie, Wadsworth &amp; Brooks/Cole.\n",
       "</p>\n",
       "<p>McCullagh P. and Nelder, J. A. (1989)\n",
       "<em>Generalized Linear Models.</em>\n",
       "London: Chapman and Hall.\n",
       "</p>\n",
       "<p>Venables, W. N. and Ripley, B. D. (2002)\n",
       "<em>Modern Applied Statistics with S.</em>\n",
       "New York: Springer.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>anova.glm</code>, <code>summary.glm</code>, etc. for\n",
       "<code>glm</code> methods,\n",
       "and the generic functions <code>anova</code>, <code>summary</code>,\n",
       "<code>effects</code>, <code>fitted.values</code>,\n",
       "and <code>residuals</code>.\n",
       "</p>\n",
       "<p><code>lm</code> for non-generalized <em>linear</em> models (which SAS\n",
       "calls GLMs, for &lsquo;general&rsquo; linear models).\n",
       "</p>\n",
       "<p><code>loglin</code> and <code>loglm</code> (package\n",
       "<a href=\"https://CRAN.R-project.org/package=MASS\"><span class=\"pkg\">MASS</span></a>) for fitting log-linear models (which binomial and\n",
       "Poisson GLMs are) to contingency tables.\n",
       "</p>\n",
       "<p><code>bigglm</code> in package <a href=\"https://CRAN.R-project.org/package=biglm\"><span class=\"pkg\">biglm</span></a> for an alternative\n",
       "way to fit GLMs to large datasets (especially those with many cases).\n",
       "</p>\n",
       "<p><code>esoph</code>, <code>infert</code> and\n",
       "<code>predict.glm</code> have examples of fitting binomial glms.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "## Dobson (1990) Page 93: Randomized Controlled Trial :\n",
       "counts &lt;- c(18,17,15,20,10,20,25,13,12)\n",
       "outcome &lt;- gl(3,1,9)\n",
       "treatment &lt;- gl(3,3)\n",
       "data.frame(treatment, outcome, counts) # showing data\n",
       "glm.D93 &lt;- glm(counts ~ outcome + treatment, family = poisson())\n",
       "anova(glm.D93)\n",
       "summary(glm.D93)\n",
       "## Computing AIC [in many ways]:\n",
       "(A0 &lt;- AIC(glm.D93))\n",
       "(ll &lt;- logLik(glm.D93))\n",
       "A1 &lt;- -2*c(ll) + 2*attr(ll, \"df\")\n",
       "A2 &lt;- glm.D93$family$aic(counts, mu=fitted(glm.D93), wt=1) +\n",
       "        2 * length(coef(glm.D93))\n",
       "stopifnot(exprs = {\n",
       "  all.equal(A0, A1)\n",
       "  all.equal(A1, A2)\n",
       "  all.equal(A1, glm.D93$aic)\n",
       "})\n",
       "\n",
       "\n",
       "## an example with offsets from Venables &amp; Ripley (2002, p.189)\n",
       "utils::data(anorexia, package = \"MASS\")\n",
       "\n",
       "anorex.1 &lt;- glm(Postwt ~ Prewt + Treat + offset(Prewt),\n",
       "                family = gaussian, data = anorexia)\n",
       "summary(anorex.1)\n",
       "\n",
       "\n",
       "# A Gamma example, from McCullagh &amp; Nelder (1989, pp. 300-2)\n",
       "clotting &lt;- data.frame(\n",
       "    u = c(5,10,15,20,30,40,60,80,100),\n",
       "    lot1 = c(118,58,42,35,27,25,21,19,18),\n",
       "    lot2 = c(69,35,26,21,18,16,13,12,12))\n",
       "summary(glm(lot1 ~ log(u), data = clotting, family = Gamma))\n",
       "summary(glm(lot2 ~ log(u), data = clotting, family = Gamma))\n",
       "## Aliased (\"S\"ingular) -&gt; 1 NA coefficient\n",
       "(fS &lt;- glm(lot2 ~ log(u) + log(u^2), data = clotting, family = Gamma))\n",
       "tools::assertError(update(fS, singular.ok=FALSE), verbose=interactive())\n",
       "## -&gt; .. \"singular fit encountered\"\n",
       "\n",
       "## Not run: \n",
       "## for an example of the use of a terms object as a formula\n",
       "demo(glm.vr)\n",
       "\n",
       "## End(Not run)</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>stats</em> version 4.0.3 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{glm}{Fitting Generalized Linear Models}{glm}\n",
       "\\methaliasA{glm.fit}{glm}{glm.fit}\n",
       "\\aliasA{weights.glm}{glm}{weights.glm}\n",
       "\\keyword{regression}{glm}\n",
       "\\keyword{logistic}{glm}\n",
       "\\keyword{log-linear}{glm}\n",
       "\\keyword{loglinear}{glm}\n",
       "\\keyword{models}{glm}\n",
       "\\keyword{regression}{glm}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "\\code{glm} is used to fit generalized linear models, specified by\n",
       "giving a symbolic description of the linear predictor and a\n",
       "description of the error distribution.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "glm(formula, family = gaussian, data, weights, subset,\n",
       "    na.action, start = NULL, etastart, mustart, offset,\n",
       "    control = list(...), model = TRUE, method = \"glm.fit\",\n",
       "    x = FALSE, y = TRUE, singular.ok = TRUE, contrasts = NULL, ...)\n",
       "\n",
       "glm.fit(x, y, weights = rep.int(1, nobs),\n",
       "        start = NULL, etastart = NULL, mustart = NULL,\n",
       "        offset = rep.int(0, nobs), family = gaussian(),\n",
       "        control = list(), intercept = TRUE, singular.ok = TRUE)\n",
       "\n",
       "## S3 method for class 'glm'\n",
       "weights(object, type = c(\"prior\", \"working\"), ...)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{formula}] an object of class \\code{\"\\LinkA{formula}{formula}\"} (or one that\n",
       "can be coerced to that class): a symbolic description of the\n",
       "model to be fitted.  The details of model specification are given\n",
       "under `Details'.\n",
       "\n",
       "\\item[\\code{family}] a description of the error distribution and link\n",
       "function to be used in the model.  For \\code{glm} this can be a\n",
       "character string naming a family function, a family function or the\n",
       "result of a call to a family function.  For \\code{glm.fit} only the\n",
       "third option is supported.  (See \\code{\\LinkA{family}{family}} for details of\n",
       "family functions.)\n",
       "\n",
       "\\item[\\code{data}] an optional data frame, list or environment (or object\n",
       "coercible by \\code{\\LinkA{as.data.frame}{as.data.frame}} to a data frame) containing\n",
       "the variables in the model.  If not found in \\code{data}, the\n",
       "variables are taken from \\code{environment(formula)},\n",
       "typically the environment from which \\code{glm} is called.\n",
       "\n",
       "\\item[\\code{weights}] an optional vector of `prior weights' to be used\n",
       "in the fitting process.  Should be \\code{NULL} or a numeric vector.\n",
       "\n",
       "\\item[\\code{subset}] an optional vector specifying a subset of observations\n",
       "to be used in the fitting process.\n",
       "\n",
       "\\item[\\code{na.action}] a function which indicates what should happen\n",
       "when the data contain \\code{NA}s.  The default is set by\n",
       "the \\code{na.action} setting of \\code{\\LinkA{options}{options}}, and is\n",
       "\\code{\\LinkA{na.fail}{na.fail}} if that is unset.  The `factory-fresh'\n",
       "default is \\code{\\LinkA{na.omit}{na.omit}}.  Another possible value is\n",
       "\\code{NULL}, no action.  Value \\code{\\LinkA{na.exclude}{na.exclude}} can be useful.\n",
       "\n",
       "\\item[\\code{start}] starting values for the parameters in the linear predictor.\n",
       "\n",
       "\\item[\\code{etastart}] starting values for the linear predictor.\n",
       "\n",
       "\\item[\\code{mustart}] starting values for the vector of means.\n",
       "\n",
       "\\item[\\code{offset}] this can be used to specify an \\emph{a priori} known\n",
       "component to be included in the linear predictor during fitting.\n",
       "This should be \\code{NULL} or a numeric vector of length equal to\n",
       "the number of cases.  One or more \\code{\\LinkA{offset}{offset}} terms can be\n",
       "included in the formula instead or as well, and if more than one is\n",
       "specified their sum is used.  See \\code{\\LinkA{model.offset}{model.offset}}.\n",
       "\n",
       "\\item[\\code{control}] a list of parameters for controlling the fitting\n",
       "process.  For \\code{glm.fit} this is passed to\n",
       "\\code{\\LinkA{glm.control}{glm.control}}.\n",
       "\n",
       "\\item[\\code{model}] a logical value indicating whether \\emph{model frame}\n",
       "should be included as a component of the returned value.\n",
       "\n",
       "\\item[\\code{method}] the method to be used in fitting the model.  The default\n",
       "method \\code{\"glm.fit\"} uses iteratively reweighted least squares\n",
       "(IWLS): the alternative \\code{\"model.frame\"} returns the model frame\n",
       "and does no fitting.\n",
       "\n",
       "User-supplied fitting functions can be supplied either as a function\n",
       "or a character string naming a function, with a function which takes\n",
       "the same arguments as \\code{glm.fit}.  If specified as a character\n",
       "string it is looked up from within the \\pkg{stats} namespace.\n",
       "\n",
       "\n",
       "\\item[\\code{x, y}] For \\code{glm}:\n",
       "logical values indicating whether the response vector and model\n",
       "matrix used in the fitting process should be returned as components\n",
       "of the returned value.\n",
       "\n",
       "For \\code{glm.fit}: \\code{x} is a design matrix of dimension\n",
       "\\code{n * p}, and \\code{y} is a vector of observations of length\n",
       "\\code{n}.\n",
       "\n",
       "\n",
       "\\item[\\code{singular.ok}] logical; if \\code{FALSE} a singular fit is an\n",
       "error.\n",
       "\\item[\\code{contrasts}] an optional list. See the \\code{contrasts.arg}\n",
       "of \\code{model.matrix.default}.\n",
       "\n",
       "\\item[\\code{intercept}] logical. Should an intercept be included in the\n",
       "\\emph{null} model?\n",
       "\n",
       "\\item[\\code{object}] an object inheriting from class \\code{\"glm\"}.\n",
       "\\item[\\code{type}] character, partial matching allowed.  Type of weights to\n",
       "extract from the fitted model object.  Can be abbreviated.\n",
       "\n",
       "\\item[\\code{...}] \n",
       "For \\code{glm}: arguments to be used to form the default\n",
       "\\code{control} argument if it is not supplied directly.\n",
       "\n",
       "For \\code{weights}: further arguments passed to or from other methods.\n",
       "\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "A typical predictor has the form \\code{response \\textasciitilde{} terms} where\n",
       "\\code{response} is the (numeric) response vector and \\code{terms} is a\n",
       "series of terms which specifies a linear predictor for\n",
       "\\code{response}.  For \\code{binomial} and \\code{quasibinomial}\n",
       "families the response can also be specified as a \\code{\\LinkA{factor}{factor}}\n",
       "(when the first level denotes failure and all others success) or as a\n",
       "two-column matrix with the columns giving the numbers of successes and\n",
       "failures.  A terms specification of the form \\code{first + second}\n",
       "indicates all the terms in \\code{first} together with all the terms in\n",
       "\\code{second} with any duplicates removed.\n",
       "\n",
       "A specification of the form \\code{first:second} indicates the set\n",
       "of terms obtained by taking the interactions of all terms in\n",
       "\\code{first} with all terms in \\code{second}.  The specification\n",
       "\\code{first*second} indicates the \\emph{cross} of \\code{first} and\n",
       "\\code{second}.  This is the same as \\code{first + second +\n",
       "  first:second}.\n",
       "\n",
       "The terms in the formula will be re-ordered so that main effects come\n",
       "first, followed by the interactions, all second-order, all third-order\n",
       "and so on: to avoid this pass a \\code{terms} object as the formula.\n",
       "\n",
       "Non-\\code{NULL} \\code{weights} can be used to indicate that different\n",
       "observations have different dispersions (with the values in\n",
       "\\code{weights} being inversely proportional to the dispersions); or\n",
       "equivalently, when the elements of \\code{weights} are positive\n",
       "integers \\eqn{w_i}{}, that each response \\eqn{y_i}{} is the mean of\n",
       "\\eqn{w_i}{} unit-weight observations.  For a binomial GLM prior weights\n",
       "are used to give the number of trials when the response is the\n",
       "proportion of successes: they would rarely be used for a Poisson GLM.\n",
       "\n",
       "\n",
       "\\code{glm.fit} is the workhorse function: it is not normally called\n",
       "directly but can be more efficient where the response vector, design\n",
       "matrix and family have already been calculated.\n",
       "\n",
       "If more than one of \\code{etastart}, \\code{start} and \\code{mustart}\n",
       "is specified, the first in the list will be used.  It is often\n",
       "advisable to supply starting values for a \\code{\\LinkA{quasi}{quasi}} family,\n",
       "and also for families with unusual links such as \\code{gaussian(\"log\")}.\n",
       "\n",
       "All of \\code{weights}, \\code{subset}, \\code{offset}, \\code{etastart}\n",
       "and \\code{mustart} are evaluated in the same way as variables in\n",
       "\\code{formula}, that is first in \\code{data} and then in the\n",
       "environment of \\code{formula}.\n",
       "\n",
       "For the background to warning messages about `fitted probabilities\n",
       "numerically 0 or 1 occurred' for binomial GLMs, see Venables \\&\n",
       "Ripley (2002, pp.~197--8).\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "\\code{glm} returns an object of class inheriting from \\code{\"glm\"}\n",
       "which inherits from the class \\code{\"lm\"}. See later in this section.\n",
       "If a non-standard \\code{method} is used, the object will also inherit\n",
       "from the class (if any) returned by that function.\n",
       "\n",
       "The function \\code{\\LinkA{summary}{summary}} (i.e., \\code{\\LinkA{summary.glm}{summary.glm}}) can\n",
       "be used to obtain or print a summary of the results and the function\n",
       "\\code{\\LinkA{anova}{anova}} (i.e., \\code{\\LinkA{anova.glm}{anova.glm}})\n",
       "to produce an analysis of variance table.\n",
       "\n",
       "The generic accessor functions \\code{\\LinkA{coefficients}{coefficients}},\n",
       "\\code{effects}, \\code{fitted.values} and \\code{residuals} can be used to\n",
       "extract various useful features of the value returned by \\code{glm}.\n",
       "\n",
       "\\code{weights} extracts a vector of weights, one for each case in the\n",
       "fit (after subsetting and \\code{na.action}).\n",
       "\n",
       "An object of class \\code{\"glm\"} is a list containing at least the\n",
       "following components:\n",
       "\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{coefficients}] a named vector of coefficients\n",
       "\\item[\\code{residuals}] the \\emph{working} residuals, that is the residuals\n",
       "in the final iteration of the IWLS fit.  Since cases with zero\n",
       "weights are omitted, their working residuals are \\code{NA}.\n",
       "\\item[\\code{fitted.values}] the fitted mean values, obtained by transforming\n",
       "the linear predictors by the inverse of the link function.\n",
       "\\item[\\code{rank}] the numeric rank of the fitted linear model.\n",
       "\\item[\\code{family}] the \\code{\\LinkA{family}{family}} object used.\n",
       "\\item[\\code{linear.predictors}] the linear fit on link scale.\n",
       "\\item[\\code{deviance}] up to a constant, minus twice the maximized\n",
       "log-likelihood.  Where sensible, the constant is chosen so that a\n",
       "saturated model has deviance zero.\n",
       "\\item[\\code{aic}] A version of Akaike's \\emph{An Information Criterion},\n",
       "minus twice the maximized log-likelihood plus twice the number of\n",
       "parameters, computed via the \\code{aic} component of the family.\n",
       "For binomial and Poison families the dispersion is\n",
       "fixed at one and the number of parameters is the number of\n",
       "coefficients.  For gaussian, Gamma and inverse gaussian families the\n",
       "dispersion is estimated from the residual deviance, and the number\n",
       "of parameters is the number of coefficients plus one.  For a\n",
       "gaussian family the MLE of the dispersion is used so this is a valid\n",
       "value of AIC, but for Gamma and inverse gaussian families it is not.\n",
       "For families fitted by quasi-likelihood the value is \\code{NA}.\n",
       "\\item[\\code{null.deviance}] The deviance for the null model, comparable with\n",
       "\\code{deviance}. The null model will include the offset, and an\n",
       "intercept if there is one in the model.  Note that this will be\n",
       "incorrect if the link function depends on the data other than\n",
       "through the fitted mean: specify a zero offset to force a correct\n",
       "calculation.\n",
       "\\item[\\code{iter}] the number of iterations of IWLS used.\n",
       "\\item[\\code{weights}] the \\emph{working} weights, that is the weights\n",
       "in the final iteration of the IWLS fit.\n",
       "\\item[\\code{prior.weights}] the weights initially supplied, a vector of\n",
       "\\code{1}s if none were.\n",
       "\\item[\\code{df.residual}] the residual degrees of freedom.\n",
       "\\item[\\code{df.null}] the residual degrees of freedom for the null model.\n",
       "\\item[\\code{y}] if requested (the default) the \\code{y} vector\n",
       "used. (It is a vector even for a binomial model.)\n",
       "\\item[\\code{x}] if requested, the model matrix.\n",
       "\\item[\\code{model}] if requested (the default), the model frame.\n",
       "\\item[\\code{converged}] logical. Was the IWLS algorithm judged to have converged?\n",
       "\\item[\\code{boundary}] logical. Is the fitted value on the boundary of the\n",
       "attainable values?\n",
       "\\item[\\code{call}] the matched call.\n",
       "\\item[\\code{formula}] the formula supplied.\n",
       "\\item[\\code{terms}] the \\code{\\LinkA{terms}{terms}} object used.\n",
       "\\item[\\code{data}] the \\code{data argument}.\n",
       "\\item[\\code{offset}] the offset vector used.\n",
       "\\item[\\code{control}] the value of the \\code{control} argument used.\n",
       "\\item[\\code{method}] the name of the fitter function used (when provided as a\n",
       "\\code{\\LinkA{character}{character}} string to \\code{glm()}) or the fitter\n",
       "\\code{\\LinkA{function}{function}} (when provided as that).\n",
       "\\item[\\code{contrasts}] (where relevant) the contrasts used.\n",
       "\\item[\\code{xlevels}] (where relevant) a record of the levels of the factors\n",
       "used in fitting.\n",
       "\\item[\\code{na.action}] (where relevant) information returned by\n",
       "\\code{\\LinkA{model.frame}{model.frame}} on the special handling of \\code{NA}s.\n",
       "\n",
       "\\end{ldescription}\n",
       "In addition, non-empty fits will have components \\code{qr}, \\code{R}\n",
       "and \\code{effects} relating to the final weighted linear fit.\n",
       "\n",
       "Objects of class \\code{\"glm\"} are normally of class \\code{c(\"glm\",\n",
       "    \"lm\")}, that is inherit from class \\code{\"lm\"}, and well-designed\n",
       "methods for class \\code{\"lm\"} will be applied to the weighted linear\n",
       "model at the final iteration of IWLS.  However, care is needed, as\n",
       "extractor functions for class \\code{\"glm\"} such as\n",
       "\\code{\\LinkA{residuals}{residuals}} and \\code{weights} do \\bold{not} just pick out\n",
       "the component of the fit with the same name.\n",
       "\n",
       "If a \\code{\\LinkA{binomial}{binomial}} \\code{glm} model was specified by giving a\n",
       "two-column response, the weights returned by \\code{prior.weights} are\n",
       "the total numbers of cases (factored by the supplied case weights) and\n",
       "the component \\code{y} of the result is the proportion of successes.\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Section}{Fitting functions}\n",
       "The argument \\code{method} serves two purposes.  One is to allow the\n",
       "model frame to be recreated with no fitting.  The other is to allow\n",
       "the default fitting function \\code{glm.fit} to be replaced by a\n",
       "function which takes the same arguments and uses a different fitting\n",
       "algorithm.  If \\code{glm.fit} is supplied as a character string it is\n",
       "used to search for a function of that name, starting in the\n",
       "\\pkg{stats} namespace.\n",
       "\n",
       "The class of the object return by the fitter (if any) will be\n",
       "prepended to the class returned by \\code{glm}.\n",
       "\\end{Section}\n",
       "%\n",
       "\\begin{Author}\\relax\n",
       "The original \\R{} implementation of \\code{glm} was written by Simon\n",
       "Davies working for Ross Ihaka at the University of Auckland, but has\n",
       "since been extensively re-written by members of the R Core team.\n",
       "\n",
       "The design was inspired by the S function of the same name described\n",
       "in Hastie \\& Pregibon (1992).\n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "Dobson, A. J. (1990)\n",
       "\\emph{An Introduction to Generalized Linear Models.}\n",
       "London: Chapman and Hall.\n",
       "\n",
       "Hastie, T. J. and Pregibon, D. (1992)\n",
       "\\emph{Generalized linear models.}\n",
       "Chapter 6 of \\emph{Statistical Models in S}\n",
       "eds J. M. Chambers and T. J. Hastie, Wadsworth \\& Brooks/Cole.\n",
       "\n",
       "McCullagh P. and Nelder, J. A. (1989)\n",
       "\\emph{Generalized Linear Models.}\n",
       "London: Chapman and Hall.\n",
       "\n",
       "Venables, W. N. and Ripley, B. D. (2002)\n",
       "\\emph{Modern Applied Statistics with S.}\n",
       "New York: Springer.\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\\code{\\LinkA{anova.glm}{anova.glm}}, \\code{\\LinkA{summary.glm}{summary.glm}}, etc. for\n",
       "\\code{glm} methods,\n",
       "and the generic functions \\code{\\LinkA{anova}{anova}}, \\code{\\LinkA{summary}{summary}},\n",
       "\\code{\\LinkA{effects}{effects}}, \\code{\\LinkA{fitted.values}{fitted.values}},\n",
       "and \\code{\\LinkA{residuals}{residuals}}.\n",
       "\n",
       "\\code{\\LinkA{lm}{lm}} for non-generalized \\emph{linear} models (which SAS\n",
       "calls GLMs, for `general' linear models).\n",
       "\n",
       "\\code{\\LinkA{loglin}{loglin}} and \\code{\\LinkA{loglm}{loglm}} (package\n",
       "\\Rhref{https://CRAN.R-project.org/package=MASS}{\\pkg{MASS}}) for fitting log-linear models (which binomial and\n",
       "Poisson GLMs are) to contingency tables.\n",
       "\n",
       "\\code{bigglm} in package \\Rhref{https://CRAN.R-project.org/package=biglm}{\\pkg{biglm}} for an alternative\n",
       "way to fit GLMs to large datasets (especially those with many cases).\n",
       "\n",
       "\\code{\\LinkA{esoph}{esoph}}, \\code{\\LinkA{infert}{infert}} and\n",
       "\\code{\\LinkA{predict.glm}{predict.glm}} have examples of fitting binomial glms.\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "## Dobson (1990) Page 93: Randomized Controlled Trial :\n",
       "counts <- c(18,17,15,20,10,20,25,13,12)\n",
       "outcome <- gl(3,1,9)\n",
       "treatment <- gl(3,3)\n",
       "data.frame(treatment, outcome, counts) # showing data\n",
       "glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())\n",
       "anova(glm.D93)\n",
       "summary(glm.D93)\n",
       "## Computing AIC [in many ways]:\n",
       "(A0 <- AIC(glm.D93))\n",
       "(ll <- logLik(glm.D93))\n",
       "A1 <- -2*c(ll) + 2*attr(ll, \"df\")\n",
       "A2 <- glm.D93$family$aic(counts, mu=fitted(glm.D93), wt=1) +\n",
       "        2 * length(coef(glm.D93))\n",
       "stopifnot(exprs = {\n",
       "  all.equal(A0, A1)\n",
       "  all.equal(A1, A2)\n",
       "  all.equal(A1, glm.D93$aic)\n",
       "})\n",
       "\n",
       "\n",
       "## an example with offsets from Venables & Ripley (2002, p.189)\n",
       "utils::data(anorexia, package = \"MASS\")\n",
       "\n",
       "anorex.1 <- glm(Postwt ~ Prewt + Treat + offset(Prewt),\n",
       "                family = gaussian, data = anorexia)\n",
       "summary(anorex.1)\n",
       "\n",
       "\n",
       "# A Gamma example, from McCullagh & Nelder (1989, pp. 300-2)\n",
       "clotting <- data.frame(\n",
       "    u = c(5,10,15,20,30,40,60,80,100),\n",
       "    lot1 = c(118,58,42,35,27,25,21,19,18),\n",
       "    lot2 = c(69,35,26,21,18,16,13,12,12))\n",
       "summary(glm(lot1 ~ log(u), data = clotting, family = Gamma))\n",
       "summary(glm(lot2 ~ log(u), data = clotting, family = Gamma))\n",
       "## Aliased (\"S\"ingular) -> 1 NA coefficient\n",
       "(fS <- glm(lot2 ~ log(u) + log(u^2), data = clotting, family = Gamma))\n",
       "tools::assertError(update(fS, singular.ok=FALSE), verbose=interactive())\n",
       "## -> .. \"singular fit encountered\"\n",
       "\n",
       "## Not run: \n",
       "## for an example of the use of a terms object as a formula\n",
       "demo(glm.vr)\n",
       "\n",
       "## End(Not run)\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "glm                   package:stats                    R Documentation\n",
       "\n",
       "_\bF_\bi_\bt_\bt_\bi_\bn_\bg _\bG_\be_\bn_\be_\br_\ba_\bl_\bi_\bz_\be_\bd _\bL_\bi_\bn_\be_\ba_\br _\bM_\bo_\bd_\be_\bl_\bs\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     'glm' is used to fit generalized linear models, specified by\n",
       "     giving a symbolic description of the linear predictor and a\n",
       "     description of the error distribution.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     glm(formula, family = gaussian, data, weights, subset,\n",
       "         na.action, start = NULL, etastart, mustart, offset,\n",
       "         control = list(...), model = TRUE, method = \"glm.fit\",\n",
       "         x = FALSE, y = TRUE, singular.ok = TRUE, contrasts = NULL, ...)\n",
       "     \n",
       "     glm.fit(x, y, weights = rep.int(1, nobs),\n",
       "             start = NULL, etastart = NULL, mustart = NULL,\n",
       "             offset = rep.int(0, nobs), family = gaussian(),\n",
       "             control = list(), intercept = TRUE, singular.ok = TRUE)\n",
       "     \n",
       "     ## S3 method for class 'glm'\n",
       "     weights(object, type = c(\"prior\", \"working\"), ...)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       " formula: an object of class '\"formula\"' (or one that can be coerced to\n",
       "          that class): a symbolic description of the model to be\n",
       "          fitted.  The details of model specification are given under\n",
       "          'Details'.\n",
       "\n",
       "  family: a description of the error distribution and link function to\n",
       "          be used in the model.  For 'glm' this can be a character\n",
       "          string naming a family function, a family function or the\n",
       "          result of a call to a family function.  For 'glm.fit' only\n",
       "          the third option is supported.  (See 'family' for details of\n",
       "          family functions.)\n",
       "\n",
       "    data: an optional data frame, list or environment (or object\n",
       "          coercible by 'as.data.frame' to a data frame) containing the\n",
       "          variables in the model.  If not found in 'data', the\n",
       "          variables are taken from 'environment(formula)', typically\n",
       "          the environment from which 'glm' is called.\n",
       "\n",
       " weights: an optional vector of 'prior weights' to be used in the\n",
       "          fitting process.  Should be 'NULL' or a numeric vector.\n",
       "\n",
       "  subset: an optional vector specifying a subset of observations to be\n",
       "          used in the fitting process.\n",
       "\n",
       "na.action: a function which indicates what should happen when the data\n",
       "          contain 'NA's.  The default is set by the 'na.action' setting\n",
       "          of 'options', and is 'na.fail' if that is unset.  The\n",
       "          'factory-fresh' default is 'na.omit'.  Another possible value\n",
       "          is 'NULL', no action.  Value 'na.exclude' can be useful.\n",
       "\n",
       "   start: starting values for the parameters in the linear predictor.\n",
       "\n",
       "etastart: starting values for the linear predictor.\n",
       "\n",
       " mustart: starting values for the vector of means.\n",
       "\n",
       "  offset: this can be used to specify an _a priori_ known component to\n",
       "          be included in the linear predictor during fitting.  This\n",
       "          should be 'NULL' or a numeric vector of length equal to the\n",
       "          number of cases.  One or more 'offset' terms can be included\n",
       "          in the formula instead or as well, and if more than one is\n",
       "          specified their sum is used.  See 'model.offset'.\n",
       "\n",
       " control: a list of parameters for controlling the fitting process.\n",
       "          For 'glm.fit' this is passed to 'glm.control'.\n",
       "\n",
       "   model: a logical value indicating whether _model frame_ should be\n",
       "          included as a component of the returned value.\n",
       "\n",
       "  method: the method to be used in fitting the model.  The default\n",
       "          method '\"glm.fit\"' uses iteratively reweighted least squares\n",
       "          (IWLS): the alternative '\"model.frame\"' returns the model\n",
       "          frame and does no fitting.\n",
       "\n",
       "          User-supplied fitting functions can be supplied either as a\n",
       "          function or a character string naming a function, with a\n",
       "          function which takes the same arguments as 'glm.fit'.  If\n",
       "          specified as a character string it is looked up from within\n",
       "          the 'stats' namespace.\n",
       "\n",
       "    x, y: For 'glm': logical values indicating whether the response\n",
       "          vector and model matrix used in the fitting process should be\n",
       "          returned as components of the returned value.\n",
       "\n",
       "          For 'glm.fit': 'x' is a design matrix of dimension 'n * p',\n",
       "          and 'y' is a vector of observations of length 'n'.\n",
       "\n",
       "singular.ok: logical; if 'FALSE' a singular fit is an error.\n",
       "\n",
       "contrasts: an optional list. See the 'contrasts.arg' of\n",
       "          'model.matrix.default'.\n",
       "\n",
       "intercept: logical. Should an intercept be included in the _null_\n",
       "          model?\n",
       "\n",
       "  object: an object inheriting from class '\"glm\"'.\n",
       "\n",
       "    type: character, partial matching allowed.  Type of weights to\n",
       "          extract from the fitted model object.  Can be abbreviated.\n",
       "\n",
       "     ...: For 'glm': arguments to be used to form the default 'control'\n",
       "          argument if it is not supplied directly.\n",
       "\n",
       "          For 'weights': further arguments passed to or from other\n",
       "          methods.\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     A typical predictor has the form 'response ~ terms' where\n",
       "     'response' is the (numeric) response vector and 'terms' is a\n",
       "     series of terms which specifies a linear predictor for 'response'.\n",
       "     For 'binomial' and 'quasibinomial' families the response can also\n",
       "     be specified as a 'factor' (when the first level denotes failure\n",
       "     and all others success) or as a two-column matrix with the columns\n",
       "     giving the numbers of successes and failures.  A terms\n",
       "     specification of the form 'first + second' indicates all the terms\n",
       "     in 'first' together with all the terms in 'second' with any\n",
       "     duplicates removed.\n",
       "\n",
       "     A specification of the form 'first:second' indicates the set of\n",
       "     terms obtained by taking the interactions of all terms in 'first'\n",
       "     with all terms in 'second'.  The specification 'first*second'\n",
       "     indicates the _cross_ of 'first' and 'second'.  This is the same\n",
       "     as 'first + second + first:second'.\n",
       "\n",
       "     The terms in the formula will be re-ordered so that main effects\n",
       "     come first, followed by the interactions, all second-order, all\n",
       "     third-order and so on: to avoid this pass a 'terms' object as the\n",
       "     formula.\n",
       "\n",
       "     Non-'NULL' 'weights' can be used to indicate that different\n",
       "     observations have different dispersions (with the values in\n",
       "     'weights' being inversely proportional to the dispersions); or\n",
       "     equivalently, when the elements of 'weights' are positive integers\n",
       "     w_i, that each response y_i is the mean of w_i unit-weight\n",
       "     observations.  For a binomial GLM prior weights are used to give\n",
       "     the number of trials when the response is the proportion of\n",
       "     successes: they would rarely be used for a Poisson GLM.\n",
       "\n",
       "     'glm.fit' is the workhorse function: it is not normally called\n",
       "     directly but can be more efficient where the response vector,\n",
       "     design matrix and family have already been calculated.\n",
       "\n",
       "     If more than one of 'etastart', 'start' and 'mustart' is\n",
       "     specified, the first in the list will be used.  It is often\n",
       "     advisable to supply starting values for a 'quasi' family, and also\n",
       "     for families with unusual links such as 'gaussian(\"log\")'.\n",
       "\n",
       "     All of 'weights', 'subset', 'offset', 'etastart' and 'mustart' are\n",
       "     evaluated in the same way as variables in 'formula', that is first\n",
       "     in 'data' and then in the environment of 'formula'.\n",
       "\n",
       "     For the background to warning messages about 'fitted probabilities\n",
       "     numerically 0 or 1 occurred' for binomial GLMs, see Venables &\n",
       "     Ripley (2002, pp. 197-8).\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     'glm' returns an object of class inheriting from '\"glm\"' which\n",
       "     inherits from the class '\"lm\"'. See later in this section.  If a\n",
       "     non-standard 'method' is used, the object will also inherit from\n",
       "     the class (if any) returned by that function.\n",
       "\n",
       "     The function 'summary' (i.e., 'summary.glm') can be used to obtain\n",
       "     or print a summary of the results and the function 'anova' (i.e.,\n",
       "     'anova.glm') to produce an analysis of variance table.\n",
       "\n",
       "     The generic accessor functions 'coefficients', 'effects',\n",
       "     'fitted.values' and 'residuals' can be used to extract various\n",
       "     useful features of the value returned by 'glm'.\n",
       "\n",
       "     'weights' extracts a vector of weights, one for each case in the\n",
       "     fit (after subsetting and 'na.action').\n",
       "\n",
       "     An object of class '\"glm\"' is a list containing at least the\n",
       "     following components:\n",
       "\n",
       "coefficients: a named vector of coefficients\n",
       "\n",
       "residuals: the _working_ residuals, that is the residuals in the final\n",
       "          iteration of the IWLS fit.  Since cases with zero weights are\n",
       "          omitted, their working residuals are 'NA'.\n",
       "\n",
       "fitted.values: the fitted mean values, obtained by transforming the\n",
       "          linear predictors by the inverse of the link function.\n",
       "\n",
       "    rank: the numeric rank of the fitted linear model.\n",
       "\n",
       "  family: the 'family' object used.\n",
       "\n",
       "linear.predictors: the linear fit on link scale.\n",
       "\n",
       "deviance: up to a constant, minus twice the maximized log-likelihood.\n",
       "          Where sensible, the constant is chosen so that a saturated\n",
       "          model has deviance zero.\n",
       "\n",
       "     aic: A version of Akaike's _An Information Criterion_, minus twice\n",
       "          the maximized log-likelihood plus twice the number of\n",
       "          parameters, computed via the 'aic' component of the family.\n",
       "          For binomial and Poison families the dispersion is fixed at\n",
       "          one and the number of parameters is the number of\n",
       "          coefficients.  For gaussian, Gamma and inverse gaussian\n",
       "          families the dispersion is estimated from the residual\n",
       "          deviance, and the number of parameters is the number of\n",
       "          coefficients plus one.  For a gaussian family the MLE of the\n",
       "          dispersion is used so this is a valid value of AIC, but for\n",
       "          Gamma and inverse gaussian families it is not.  For families\n",
       "          fitted by quasi-likelihood the value is 'NA'.\n",
       "\n",
       "null.deviance: The deviance for the null model, comparable with\n",
       "          'deviance'. The null model will include the offset, and an\n",
       "          intercept if there is one in the model.  Note that this will\n",
       "          be incorrect if the link function depends on the data other\n",
       "          than through the fitted mean: specify a zero offset to force\n",
       "          a correct calculation.\n",
       "\n",
       "    iter: the number of iterations of IWLS used.\n",
       "\n",
       " weights: the _working_ weights, that is the weights in the final\n",
       "          iteration of the IWLS fit.\n",
       "\n",
       "prior.weights: the weights initially supplied, a vector of '1's if none\n",
       "          were.\n",
       "\n",
       "df.residual: the residual degrees of freedom.\n",
       "\n",
       " df.null: the residual degrees of freedom for the null model.\n",
       "\n",
       "       y: if requested (the default) the 'y' vector used. (It is a\n",
       "          vector even for a binomial model.)\n",
       "\n",
       "       x: if requested, the model matrix.\n",
       "\n",
       "   model: if requested (the default), the model frame.\n",
       "\n",
       "converged: logical. Was the IWLS algorithm judged to have converged?\n",
       "\n",
       "boundary: logical. Is the fitted value on the boundary of the\n",
       "          attainable values?\n",
       "\n",
       "    call: the matched call.\n",
       "\n",
       " formula: the formula supplied.\n",
       "\n",
       "   terms: the 'terms' object used.\n",
       "\n",
       "    data: the 'data argument'.\n",
       "\n",
       "  offset: the offset vector used.\n",
       "\n",
       " control: the value of the 'control' argument used.\n",
       "\n",
       "  method: the name of the fitter function used (when provided as a\n",
       "          'character' string to 'glm()') or the fitter 'function' (when\n",
       "          provided as that).\n",
       "\n",
       "contrasts: (where relevant) the contrasts used.\n",
       "\n",
       " xlevels: (where relevant) a record of the levels of the factors used\n",
       "          in fitting.\n",
       "\n",
       "na.action: (where relevant) information returned by 'model.frame' on\n",
       "          the special handling of 'NA's.\n",
       "     In addition, non-empty fits will have components 'qr', 'R' and\n",
       "     'effects' relating to the final weighted linear fit.\n",
       "\n",
       "     Objects of class '\"glm\"' are normally of class 'c(\"glm\", \"lm\")',\n",
       "     that is inherit from class '\"lm\"', and well-designed methods for\n",
       "     class '\"lm\"' will be applied to the weighted linear model at the\n",
       "     final iteration of IWLS.  However, care is needed, as extractor\n",
       "     functions for class '\"glm\"' such as 'residuals' and 'weights' do\n",
       "     *not* just pick out the component of the fit with the same name.\n",
       "\n",
       "     If a 'binomial' 'glm' model was specified by giving a two-column\n",
       "     response, the weights returned by 'prior.weights' are the total\n",
       "     numbers of cases (factored by the supplied case weights) and the\n",
       "     component 'y' of the result is the proportion of successes.\n",
       "\n",
       "_\bF_\bi_\bt_\bt_\bi_\bn_\bg _\bf_\bu_\bn_\bc_\bt_\bi_\bo_\bn_\bs:\n",
       "\n",
       "     The argument 'method' serves two purposes.  One is to allow the\n",
       "     model frame to be recreated with no fitting.  The other is to\n",
       "     allow the default fitting function 'glm.fit' to be replaced by a\n",
       "     function which takes the same arguments and uses a different\n",
       "     fitting algorithm.  If 'glm.fit' is supplied as a character string\n",
       "     it is used to search for a function of that name, starting in the\n",
       "     'stats' namespace.\n",
       "\n",
       "     The class of the object return by the fitter (if any) will be\n",
       "     prepended to the class returned by 'glm'.\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     The original R implementation of 'glm' was written by Simon Davies\n",
       "     working for Ross Ihaka at the University of Auckland, but has\n",
       "     since been extensively re-written by members of the R Core team.\n",
       "\n",
       "     The design was inspired by the S function of the same name\n",
       "     described in Hastie & Pregibon (1992).\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Dobson, A. J. (1990) _An Introduction to Generalized Linear\n",
       "     Models._ London: Chapman and Hall.\n",
       "\n",
       "     Hastie, T. J. and Pregibon, D. (1992) _Generalized linear models._\n",
       "     Chapter 6 of _Statistical Models in S_ eds J. M. Chambers and T.\n",
       "     J. Hastie, Wadsworth & Brooks/Cole.\n",
       "\n",
       "     McCullagh P. and Nelder, J. A. (1989) _Generalized Linear Models._\n",
       "     London: Chapman and Hall.\n",
       "\n",
       "     Venables, W. N. and Ripley, B. D. (2002) _Modern Applied\n",
       "     Statistics with S._ New York: Springer.\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     'anova.glm', 'summary.glm', etc. for 'glm' methods, and the\n",
       "     generic functions 'anova', 'summary', 'effects', 'fitted.values',\n",
       "     and 'residuals'.\n",
       "\n",
       "     'lm' for non-generalized _linear_ models (which SAS calls GLMs,\n",
       "     for 'general' linear models).\n",
       "\n",
       "     'loglin' and 'loglm' (package 'MASS') for fitting log-linear\n",
       "     models (which binomial and Poisson GLMs are) to contingency\n",
       "     tables.\n",
       "\n",
       "     'bigglm' in package 'biglm' for an alternative way to fit GLMs to\n",
       "     large datasets (especially those with many cases).\n",
       "\n",
       "     'esoph', 'infert' and 'predict.glm' have examples of fitting\n",
       "     binomial glms.\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     ## Dobson (1990) Page 93: Randomized Controlled Trial :\n",
       "     counts <- c(18,17,15,20,10,20,25,13,12)\n",
       "     outcome <- gl(3,1,9)\n",
       "     treatment <- gl(3,3)\n",
       "     data.frame(treatment, outcome, counts) # showing data\n",
       "     glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())\n",
       "     anova(glm.D93)\n",
       "     summary(glm.D93)\n",
       "     ## Computing AIC [in many ways]:\n",
       "     (A0 <- AIC(glm.D93))\n",
       "     (ll <- logLik(glm.D93))\n",
       "     A1 <- -2*c(ll) + 2*attr(ll, \"df\")\n",
       "     A2 <- glm.D93$family$aic(counts, mu=fitted(glm.D93), wt=1) +\n",
       "             2 * length(coef(glm.D93))\n",
       "     stopifnot(exprs = {\n",
       "       all.equal(A0, A1)\n",
       "       all.equal(A1, A2)\n",
       "       all.equal(A1, glm.D93$aic)\n",
       "     })\n",
       "     \n",
       "     \n",
       "     ## an example with offsets from Venables & Ripley (2002, p.189)\n",
       "     utils::data(anorexia, package = \"MASS\")\n",
       "     \n",
       "     anorex.1 <- glm(Postwt ~ Prewt + Treat + offset(Prewt),\n",
       "                     family = gaussian, data = anorexia)\n",
       "     summary(anorex.1)\n",
       "     \n",
       "     \n",
       "     # A Gamma example, from McCullagh & Nelder (1989, pp. 300-2)\n",
       "     clotting <- data.frame(\n",
       "         u = c(5,10,15,20,30,40,60,80,100),\n",
       "         lot1 = c(118,58,42,35,27,25,21,19,18),\n",
       "         lot2 = c(69,35,26,21,18,16,13,12,12))\n",
       "     summary(glm(lot1 ~ log(u), data = clotting, family = Gamma))\n",
       "     summary(glm(lot2 ~ log(u), data = clotting, family = Gamma))\n",
       "     ## Aliased (\"S\"ingular) -> 1 NA coefficient\n",
       "     (fS <- glm(lot2 ~ log(u) + log(u^2), data = clotting, family = Gamma))\n",
       "     tools::assertError(update(fS, singular.ok=FALSE), verbose=interactive())\n",
       "     ## -> .. \"singular fit encountered\"\n",
       "     \n",
       "     ## Not run:\n",
       "     \n",
       "     ## for an example of the use of a terms object as a formula\n",
       "     demo(glm.vr)\n",
       "     ## End(Not run)\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Species ~ ., family = \"binomial\", data = dset)\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-1.87365  -0.89513  -0.05501   0.96084   2.35669  \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)  -13.0460     3.0974  -4.212 2.53e-05 ***\n",
       "Sepal.Length   1.9024     0.5169   3.680 0.000233 ***\n",
       "Sepal.Width    0.4047     0.8628   0.469 0.639077    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 138.63  on 99  degrees of freedom\n",
       "Residual deviance: 110.33  on 97  degrees of freedom\n",
       "AIC: 116.33\n",
       "\n",
       "Number of Fisher Scoring iterations: 4\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_mod = glm(formula=Species~.,data=dset,family=\"binomial\")\n",
    "summary(log_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p = logistic(X\\beta) \\leftrightarrow logit(p) = log(p/(1-p)) = X\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>51</dt><dd>1.56550699809268</dd><dt>52</dt><dd>0.424081866986154</dd><dt>53</dt><dd>1.3348035350163</dd><dt>54</dt><dd>-1.65224930070126</dd><dt>55</dt><dd>0.452455623936074</dd><dt>56</dt><dd>-1.06944455087263</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[51] 1.56550699809268\n",
       "\\item[52] 0.424081866986154\n",
       "\\item[53] 1.3348035350163\n",
       "\\item[54] -1.65224930070126\n",
       "\\item[55] 0.452455623936074\n",
       "\\item[56] -1.06944455087263\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "51\n",
       ":   1.5655069980926852\n",
       ":   0.42408186698615453\n",
       ":   1.334803535016354\n",
       ":   -1.6522493007012655\n",
       ":   0.45245562393607456\n",
       ":   -1.06944455087263\n",
       "\n"
      ],
      "text/plain": [
       "        51         52         53         54         55         56 \n",
       " 1.5655070  0.4240819  1.3348035 -1.6522493  0.4524556 -1.0694446 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(predict(log_mod))## predicts the log-odds = logit(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 6 × 3 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>(Intercept)</th><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>51</th><td>1</td><td>7.0</td><td>3.2</td></tr>\n",
       "\t<tr><th scope=row>52</th><td>1</td><td>6.4</td><td>3.2</td></tr>\n",
       "\t<tr><th scope=row>53</th><td>1</td><td>6.9</td><td>3.1</td></tr>\n",
       "\t<tr><th scope=row>54</th><td>1</td><td>5.5</td><td>2.3</td></tr>\n",
       "\t<tr><th scope=row>55</th><td>1</td><td>6.5</td><td>2.8</td></tr>\n",
       "\t<tr><th scope=row>56</th><td>1</td><td>5.7</td><td>2.8</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 3 of type dbl\n",
       "\\begin{tabular}{r|lll}\n",
       "  & (Intercept) & Sepal.Length & Sepal.Width\\\\\n",
       "\\hline\n",
       "\t51 & 1 & 7.0 & 3.2\\\\\n",
       "\t52 & 1 & 6.4 & 3.2\\\\\n",
       "\t53 & 1 & 6.9 & 3.1\\\\\n",
       "\t54 & 1 & 5.5 & 2.3\\\\\n",
       "\t55 & 1 & 6.5 & 2.8\\\\\n",
       "\t56 & 1 & 5.7 & 2.8\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 3 of type dbl\n",
       "\n",
       "| <!--/--> | (Intercept) | Sepal.Length | Sepal.Width |\n",
       "|---|---|---|---|\n",
       "| 51 | 1 | 7.0 | 3.2 |\n",
       "| 52 | 1 | 6.4 | 3.2 |\n",
       "| 53 | 1 | 6.9 | 3.1 |\n",
       "| 54 | 1 | 5.5 | 2.3 |\n",
       "| 55 | 1 | 6.5 | 2.8 |\n",
       "| 56 | 1 | 5.7 | 2.8 |\n",
       "\n"
      ],
      "text/plain": [
       "   (Intercept) Sepal.Length Sepal.Width\n",
       "51 1           7.0          3.2        \n",
       "52 1           6.4          3.2        \n",
       "53 1           6.9          3.1        \n",
       "54 1           5.5          2.3        \n",
       "55 1           6.5          2.8        \n",
       "56 1           5.7          2.8        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_design = model.matrix(log_mod)\n",
    "head(X_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 1 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td>-13.0460297</td></tr>\n",
       "\t<tr><td>  1.9023752</td></tr>\n",
       "\t<tr><td>  0.4046594</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 1 of type dbl\n",
       "\\begin{tabular}{l}\n",
       "\t -13.0460297\\\\\n",
       "\t   1.9023752\\\\\n",
       "\t   0.4046594\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 1 of type dbl\n",
       "\n",
       "| -13.0460297 |\n",
       "|   1.9023752 |\n",
       "|   0.4046594 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]       \n",
       "[1,] -13.0460297\n",
       "[2,]   1.9023752\n",
       "[3,]   0.4046594"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_hat = log_mod$coefficients\n",
    "beta_hat = array(beta_hat,c(3,1))\n",
    "beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 6 × 1 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>51</th><td> 1.5655070</td></tr>\n",
       "\t<tr><th scope=row>52</th><td> 0.4240819</td></tr>\n",
       "\t<tr><th scope=row>53</th><td> 1.3348035</td></tr>\n",
       "\t<tr><th scope=row>54</th><td>-1.6522493</td></tr>\n",
       "\t<tr><th scope=row>55</th><td> 0.4524556</td></tr>\n",
       "\t<tr><th scope=row>56</th><td>-1.0694446</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 6 × 1 of type dbl\n",
       "\\begin{tabular}{r|l}\n",
       "\t51 &  1.5655070\\\\\n",
       "\t52 &  0.4240819\\\\\n",
       "\t53 &  1.3348035\\\\\n",
       "\t54 & -1.6522493\\\\\n",
       "\t55 &  0.4524556\\\\\n",
       "\t56 & -1.0694446\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 6 × 1 of type dbl\n",
       "\n",
       "| 51 |  1.5655070 |\n",
       "| 52 |  0.4240819 |\n",
       "| 53 |  1.3348035 |\n",
       "| 54 | -1.6522493 |\n",
       "| 55 |  0.4524556 |\n",
       "| 56 | -1.0694446 |\n",
       "\n"
      ],
      "text/plain": [
       "   [,1]      \n",
       "51  1.5655070\n",
       "52  0.4240819\n",
       "53  1.3348035\n",
       "54 -1.6522493\n",
       "55  0.4524556\n",
       "56 -1.0694446"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(X_design%*%beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>51</dt><dd>0.827142151707128</dd><dt>52</dt><dd>0.604459591016596</dd><dt>53</dt><dd>0.79163408577401</dd><dt>54</dt><dd>0.160805181843393</dd><dt>55</dt><dd>0.611222921667735</dd><dt>56</dt><dd>0.255508729588088</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[51] 0.827142151707128\n",
       "\\item[52] 0.604459591016596\n",
       "\\item[53] 0.79163408577401\n",
       "\\item[54] 0.160805181843393\n",
       "\\item[55] 0.611222921667735\n",
       "\\item[56] 0.255508729588088\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "51\n",
       ":   0.82714215170712852\n",
       ":   0.60445959101659653\n",
       ":   0.7916340857740154\n",
       ":   0.16080518184339355\n",
       ":   0.61122292166773556\n",
       ":   0.255508729588088\n",
       "\n"
      ],
      "text/plain": [
       "       51        52        53        54        55        56 \n",
       "0.8271422 0.6044596 0.7916341 0.1608052 0.6112229 0.2555087 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_hats = predict(log_mod,type=\"response\")\n",
    "head(p_hats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>51</dt><dd>1.56550699809268</dd><dt>52</dt><dd>0.424081866986154</dd><dt>53</dt><dd>1.3348035350163</dd><dt>54</dt><dd>-1.65224930070126</dd><dt>55</dt><dd>0.452455623936074</dd><dt>56</dt><dd>-1.06944455087263</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[51] 1.56550699809268\n",
       "\\item[52] 0.424081866986154\n",
       "\\item[53] 1.3348035350163\n",
       "\\item[54] -1.65224930070126\n",
       "\\item[55] 0.452455623936074\n",
       "\\item[56] -1.06944455087263\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "51\n",
       ":   1.5655069980926852\n",
       ":   0.42408186698615453\n",
       ":   1.334803535016354\n",
       ":   -1.6522493007012655\n",
       ":   0.45245562393607456\n",
       ":   -1.06944455087263\n",
       "\n"
      ],
      "text/plain": [
       "        51         52         53         54         55         56 \n",
       " 1.5655070  0.4240819  1.3348035 -1.6522493  0.4524556 -1.0694446 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>51</dt><dd>1.56550699809268</dd><dt>52</dt><dd>0.424081866986154</dd><dt>53</dt><dd>1.3348035350163</dd><dt>54</dt><dd>-1.65224930070126</dd><dt>55</dt><dd>0.452455623936074</dd><dt>56</dt><dd>-1.06944455087263</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[51] 1.56550699809268\n",
       "\\item[52] 0.424081866986154\n",
       "\\item[53] 1.3348035350163\n",
       "\\item[54] -1.65224930070126\n",
       "\\item[55] 0.452455623936074\n",
       "\\item[56] -1.06944455087263\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "51\n",
       ":   1.5655069980926852\n",
       ":   0.42408186698615453\n",
       ":   1.334803535016354\n",
       ":   -1.6522493007012655\n",
       ":   0.45245562393607456\n",
       ":   -1.06944455087263\n",
       "\n"
      ],
      "text/plain": [
       "        51         52         53         54         55         56 \n",
       " 1.5655070  0.4240819  1.3348035 -1.6522493  0.4524556 -1.0694446 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(predict(log_mod))\n",
    "head(log(p_hats/(1-p_hats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>1</li><li>1</li><li>1</li><li>0</li><li>1</li><li>0</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 1\n",
       "3. 1\n",
       "4. 0\n",
       "5. 1\n",
       "6. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1 1 1 0 1 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_pred = as.numeric(p_hats > .5)\n",
    "head(train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>virginica</li><li>virginica</li><li>virginica</li><li>versicolor</li><li>virginica</li><li>versicolor</li></ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<style>\n",
       "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
       "\t.list-inline>li {display: inline-block}\n",
       "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "\t</style>\n",
       "\t<ol class=list-inline><li>'versicolor'</li><li>'virginica'</li></ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'versicolor'\n",
       "\\item 'virginica'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. virginica\n",
       "2. virginica\n",
       "3. virginica\n",
       "4. versicolor\n",
       "5. virginica\n",
       "6. versicolor\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'versicolor'\n",
       "2. 'virginica'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] virginica  virginica  virginica  versicolor virginica  versicolor\n",
       "Levels: versicolor virginica"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_pred = factor(train_pred,labels=c('versicolor','virginica'))\n",
    "head(train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "\n",
      "Loading required package: ggplot2\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "            Reference\n",
       "Prediction   versicolor virginica\n",
       "  versicolor         38        13\n",
       "  virginica          12        37\n",
       "                                          \n",
       "               Accuracy : 0.75            \n",
       "                 95% CI : (0.6534, 0.8312)\n",
       "    No Information Rate : 0.5             \n",
       "    P-Value [Acc > NIR] : 2.818e-07       \n",
       "                                          \n",
       "                  Kappa : 0.5             \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 1               \n",
       "                                          \n",
       "            Sensitivity : 0.7600          \n",
       "            Specificity : 0.7400          \n",
       "         Pos Pred Value : 0.7451          \n",
       "         Neg Pred Value : 0.7551          \n",
       "             Prevalence : 0.5000          \n",
       "         Detection Rate : 0.3800          \n",
       "   Detection Prevalence : 0.5100          \n",
       "      Balanced Accuracy : 0.7500          \n",
       "                                          \n",
       "       'Positive' Class : versicolor      \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library('caret')\n",
    "confusionMatrix(data=train_pred,reference=dset$Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mod = function(mod){\n",
    "    x1r = range(dset$Sepal.Length)\n",
    "    x2r = range(dset$Sepal.Width)\n",
    "    x1s = seq(x1r[1],x1r[2],.01)\n",
    "    x2s = seq(x2r[1],x2r[2],.01)\n",
    "    grd = expand.grid(x1s,x2s)\n",
    "    colnames(grd) = c('Sepal.Length','Sepal.Width')\n",
    "    p_hats = predict(mod,newdata=grd,type='response')\n",
    "    train_pred = (p_hats>.5)*1\n",
    "    grd_pred = factor(train_pred,labels=c('versicolor','virginica'))\n",
    "    grd_df = cbind(grd,grd_pred)\n",
    "    colnames(grd_df) = c('Sepal.Length','Sepal.Width','Pred')\n",
    "    ggplot(data=grd_df,mapping=aes(x=Sepal.Length,y=Sepal.Width,fill=Pred))+geom_tile()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAP1BMVEUAAAAAv8QzMzNNTU1o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\ngg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mod(log_mod)+geom_point(data=dset,mapping=aes(x=Sepal.Length,y=Sepal.Width,shape=Species),inherit.aes=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "library('nnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    setosa versicolor  virginica \n",
       "        50         50         50 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dset2 = iris[,c(\"Sepal.Length\",\"Sepal.Width\",\"Species\")]\n",
    "table(dset2$Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for multinom {nnet}\"><tr><td>multinom {nnet}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>\n",
       "Fit Multinomial Log-linear Models\n",
       "</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Fits multinomial log-linear models via neural networks.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "multinom(formula, data, weights, subset, na.action,\n",
       "         contrasts = NULL, Hess = FALSE, summ = 0, censored = FALSE,\n",
       "         model = FALSE, ...)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>formula</code></td>\n",
       "<td>\n",
       "\n",
       "<p>a formula expression as for regression models, of the form\n",
       "<code>response ~ predictors</code>. The response should be a factor or a\n",
       "matrix with K columns, which will be interpreted as counts for each of\n",
       "K classes.\n",
       "A log-linear model is fitted, with coefficients zero for the first\n",
       "class. An offset can be included: it should be a numeric matrix with K columns\n",
       "if the response is either a matrix with K columns or a factor with K &gt;= 2\n",
       "classes, or a numeric vector for a response factor with 2 levels.\n",
       "See the documentation of <code>formula()</code> for other details.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>data</code></td>\n",
       "<td>\n",
       "\n",
       "<p>an optional data frame in which to interpret the variables occurring\n",
       "in <code>formula</code>.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>weights</code></td>\n",
       "<td>\n",
       "\n",
       "<p>optional case weights in fitting.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>subset</code></td>\n",
       "<td>\n",
       "\n",
       "<p>expression saying which subset of the rows of the data should  be used\n",
       "in the fit. All observations are included by default.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>na.action</code></td>\n",
       "<td>\n",
       "\n",
       "<p>a function to filter missing data.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>contrasts</code></td>\n",
       "<td>\n",
       "\n",
       "<p>a list of contrasts to be used for some or all of\n",
       "the factors appearing as variables in the model formula.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>Hess</code></td>\n",
       "<td>\n",
       "\n",
       "<p>logical for whether the Hessian (the observed/expected information matrix)\n",
       "should be returned.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>summ</code></td>\n",
       "<td>\n",
       "\n",
       "<p>integer; if non-zero summarize by deleting duplicate rows and adjust weights.\n",
       "Methods 1 and 2 differ in speed (2 uses <code>C</code>); method 3 also combines rows\n",
       "with the same X and different Y, which changes the baseline for the\n",
       "deviance.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>censored</code></td>\n",
       "<td>\n",
       "\n",
       "<p>If Y is a matrix with <code>K</code> columns, interpret the entries as one\n",
       "for possible classes, zero for impossible classes, rather than as\n",
       "counts.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>model</code></td>\n",
       "<td>\n",
       "\n",
       "<p>logical. If true, the model frame is saved as component <code>model</code>\n",
       "of the returned object.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "\n",
       "<p>additional arguments for <code>nnet</code>\n",
       "</p>\n",
       "</td></tr></table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p><code>multinom</code> calls <code>nnet</code>.  The variables on the rhs of\n",
       "the formula should be roughly scaled to [0,1] or the fit will be slow\n",
       "or may not converge at all.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>A <code>nnet</code> object with additional components:\n",
       "</p>\n",
       "<table summary=\"R valueblock\">\n",
       "<tr valign=\"top\"><td><code>deviance</code></td>\n",
       "<td>\n",
       "\n",
       "<p>the residual deviance, compared to the full saturated model (that\n",
       "explains individual observations exactly).  Also, minus twice log-likelihood.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>edf</code></td>\n",
       "<td>\n",
       "\n",
       "<p>the (effective) number of degrees of freedom used by the model\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>AIC</code></td>\n",
       "<td>\n",
       "\n",
       "<p>the AIC for this fit.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>Hessian</code></td>\n",
       "<td>\n",
       "\n",
       "<p>(if <code>Hess</code> is true).\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>model</code></td>\n",
       "<td>\n",
       "\n",
       "<p>(if <code>model</code> is true).\n",
       "</p>\n",
       "</td></tr></table>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "<p>Venables, W. N. and Ripley, B. D. (2002)\n",
       "<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>nnet</code>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "oc &lt;- options(contrasts = c(\"contr.treatment\", \"contr.poly\"))\n",
       "library(MASS)\n",
       "example(birthwt)\n",
       "(bwt.mu &lt;- multinom(low ~ ., bwt))\n",
       "options(oc)\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>nnet</em> version 7.3-14 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{multinom}{Fit Multinomial Log-linear Models}{multinom}\n",
       "\\aliasA{add1.multinom}{multinom}{add1.multinom}\n",
       "\\aliasA{anova.multinom}{multinom}{anova.multinom}\n",
       "\\aliasA{coef.multinom}{multinom}{coef.multinom}\n",
       "\\aliasA{drop1.multinom}{multinom}{drop1.multinom}\n",
       "\\aliasA{extractAIC.multinom}{multinom}{extractAIC.multinom}\n",
       "\\aliasA{logLik.multinom}{multinom}{logLik.multinom}\n",
       "\\aliasA{model.frame.multinom}{multinom}{model.frame.multinom}\n",
       "\\aliasA{predict.multinom}{multinom}{predict.multinom}\n",
       "\\aliasA{print.multinom}{multinom}{print.multinom}\n",
       "\\aliasA{print.summary.multinom}{multinom}{print.summary.multinom}\n",
       "\\aliasA{summary.multinom}{multinom}{summary.multinom}\n",
       "\\aliasA{vcov.multinom}{multinom}{vcov.multinom}\n",
       "\\keyword{multiple logistic}{multinom}\n",
       "\\keyword{neural}{multinom}\n",
       "\\keyword{models}{multinom}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Fits multinomial log-linear models via neural networks.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "multinom(formula, data, weights, subset, na.action,\n",
       "         contrasts = NULL, Hess = FALSE, summ = 0, censored = FALSE,\n",
       "         model = FALSE, ...)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{formula}] \n",
       "a formula expression as for regression models, of the form\n",
       "\\code{response \\textasciitilde{} predictors}. The response should be a factor or a\n",
       "matrix with K columns, which will be interpreted as counts for each of\n",
       "K classes.\n",
       "A log-linear model is fitted, with coefficients zero for the first\n",
       "class. An offset can be included: it should be a numeric matrix with K columns\n",
       "if the response is either a matrix with K columns or a factor with K >= 2\n",
       "classes, or a numeric vector for a response factor with 2 levels.\n",
       "See the documentation of \\code{\\LinkA{formula}{formula}()} for other details.\n",
       "\n",
       "\\item[\\code{data}] \n",
       "an optional data frame in which to interpret the variables occurring\n",
       "in \\code{formula}.\n",
       "\n",
       "\\item[\\code{weights}] \n",
       "optional case weights in fitting.\n",
       "\n",
       "\\item[\\code{subset}] \n",
       "expression saying which subset of the rows of the data should  be used\n",
       "in the fit. All observations are included by default.\n",
       "\n",
       "\\item[\\code{na.action}] \n",
       "a function to filter missing data.\n",
       "\n",
       "\\item[\\code{contrasts}] \n",
       "a list of contrasts to be used for some or all of\n",
       "the factors appearing as variables in the model formula.\n",
       "\n",
       "\\item[\\code{Hess}] \n",
       "logical for whether the Hessian (the observed/expected information matrix)\n",
       "should be returned.\n",
       "\n",
       "\\item[\\code{summ}] \n",
       "integer; if non-zero summarize by deleting duplicate rows and adjust weights.\n",
       "Methods 1 and 2 differ in speed (2 uses \\code{C}); method 3 also combines rows\n",
       "with the same X and different Y, which changes the baseline for the\n",
       "deviance.\n",
       "\n",
       "\\item[\\code{censored}] \n",
       "If Y is a matrix with \\code{K} columns, interpret the entries as one\n",
       "for possible classes, zero for impossible classes, rather than as\n",
       "counts.\n",
       "\n",
       "\\item[\\code{model}] \n",
       "logical. If true, the model frame is saved as component \\code{model}\n",
       "of the returned object.\n",
       "\n",
       "\\item[\\code{...}] \n",
       "additional arguments for \\code{nnet}\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "\\code{multinom} calls \\code{\\LinkA{nnet}{nnet}}.  The variables on the rhs of\n",
       "the formula should be roughly scaled to [0,1] or the fit will be slow\n",
       "or may not converge at all.\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "A \\code{nnet} object with additional components:\n",
       "\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{deviance}] \n",
       "the residual deviance, compared to the full saturated model (that\n",
       "explains individual observations exactly).  Also, minus twice log-likelihood.\n",
       "\n",
       "\\item[\\code{edf}] \n",
       "the (effective) number of degrees of freedom used by the model\n",
       "\n",
       "\\item[\\code{AIC}] \n",
       "the AIC for this fit.\n",
       "\n",
       "\\item[\\code{Hessian}] \n",
       "(if \\code{Hess} is true).\n",
       "\n",
       "\\item[\\code{model}] \n",
       "(if \\code{model} is true).\n",
       "\\end{ldescription}\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "Venables, W. N. and Ripley, B. D. (2002)\n",
       "\\emph{Modern Applied Statistics with S.} Fourth edition.  Springer.\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\\code{\\LinkA{nnet}{nnet}}\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "oc <- options(contrasts = c(\"contr.treatment\", \"contr.poly\"))\n",
       "library(MASS)\n",
       "example(birthwt)\n",
       "(bwt.mu <- multinom(low ~ ., bwt))\n",
       "options(oc)\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "multinom                 package:nnet                  R Documentation\n",
       "\n",
       "_\bF_\bi_\bt _\bM_\bu_\bl_\bt_\bi_\bn_\bo_\bm_\bi_\ba_\bl _\bL_\bo_\bg-_\bl_\bi_\bn_\be_\ba_\br _\bM_\bo_\bd_\be_\bl_\bs\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Fits multinomial log-linear models via neural networks.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     multinom(formula, data, weights, subset, na.action,\n",
       "              contrasts = NULL, Hess = FALSE, summ = 0, censored = FALSE,\n",
       "              model = FALSE, ...)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       " formula: a formula expression as for regression models, of the form\n",
       "          'response ~ predictors'. The response should be a factor or a\n",
       "          matrix with K columns, which will be interpreted as counts\n",
       "          for each of K classes. A log-linear model is fitted, with\n",
       "          coefficients zero for the first class. An offset can be\n",
       "          included: it should be a numeric matrix with K columns if the\n",
       "          response is either a matrix with K columns or a factor with K\n",
       "          >= 2 classes, or a numeric vector for a response factor with\n",
       "          2 levels. See the documentation of 'formula()' for other\n",
       "          details.\n",
       "\n",
       "    data: an optional data frame in which to interpret the variables\n",
       "          occurring in 'formula'.\n",
       "\n",
       " weights: optional case weights in fitting.\n",
       "\n",
       "  subset: expression saying which subset of the rows of the data should\n",
       "          be used in the fit. All observations are included by default.\n",
       "\n",
       "na.action: a function to filter missing data.\n",
       "\n",
       "contrasts: a list of contrasts to be used for some or all of the\n",
       "          factors appearing as variables in the model formula.\n",
       "\n",
       "    Hess: logical for whether the Hessian (the observed/expected\n",
       "          information matrix) should be returned.\n",
       "\n",
       "    summ: integer; if non-zero summarize by deleting duplicate rows and\n",
       "          adjust weights. Methods 1 and 2 differ in speed (2 uses 'C');\n",
       "          method 3 also combines rows with the same X and different Y,\n",
       "          which changes the baseline for the deviance.\n",
       "\n",
       "censored: If Y is a matrix with 'K' columns, interpret the entries as\n",
       "          one for possible classes, zero for impossible classes, rather\n",
       "          than as counts.\n",
       "\n",
       "   model: logical. If true, the model frame is saved as component\n",
       "          'model' of the returned object.\n",
       "\n",
       "     ...: additional arguments for 'nnet'\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     'multinom' calls 'nnet'.  The variables on the rhs of the formula\n",
       "     should be roughly scaled to [0,1] or the fit will be slow or may\n",
       "     not converge at all.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     A 'nnet' object with additional components:\n",
       "\n",
       "deviance: the residual deviance, compared to the full saturated model\n",
       "          (that explains individual observations exactly).  Also, minus\n",
       "          twice log-likelihood.\n",
       "\n",
       "     edf: the (effective) number of degrees of freedom used by the\n",
       "          model\n",
       "\n",
       "     AIC: the AIC for this fit.\n",
       "\n",
       " Hessian: (if 'Hess' is true).\n",
       "\n",
       "   model: (if 'model' is true).\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Venables, W. N. and Ripley, B. D. (2002) _Modern Applied\n",
       "     Statistics with S._ Fourth edition.  Springer.\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     'nnet'\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     oc <- options(contrasts = c(\"contr.treatment\", \"contr.poly\"))\n",
       "     library(MASS)\n",
       "     example(birthwt)\n",
       "     (bwt.mu <- multinom(low ~ ., bwt))\n",
       "     options(oc)\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?multinom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  12 (6 variable)\n",
      "initial  value 164.791843 \n",
      "iter  10 value 62.715967\n",
      "iter  20 value 59.808291\n",
      "iter  30 value 55.445984\n",
      "iter  40 value 55.375704\n",
      "iter  50 value 55.346472\n",
      "iter  60 value 55.301707\n",
      "iter  70 value 55.253532\n",
      "iter  80 value 55.243230\n",
      "iter  90 value 55.230241\n",
      "iter 100 value 55.212479\n",
      "final  value 55.212479 \n",
      "stopped after 100 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Call:\n",
       "multinom(formula = Species ~ ., data = dset2)\n",
       "\n",
       "Coefficients:\n",
       "           (Intercept) Sepal.Length Sepal.Width\n",
       "versicolor   -92.09924     40.40326   -40.58755\n",
       "virginica   -105.10096     42.30094   -40.18799\n",
       "\n",
       "Std. Errors:\n",
       "           (Intercept) Sepal.Length Sepal.Width\n",
       "versicolor    26.27831     9.142717    27.77772\n",
       "virginica     26.37025     9.131119    27.78875\n",
       "\n",
       "Residual Deviance: 110.425 \n",
       "AIC: 122.425 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>setosa</li><li>virginica</li><li>virginica</li><li>virginica</li><li>versicolor</li><li>virginica</li><li>versicolor</li><li>virginica</li><li>versicolor</li><li>virginica</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>virginica</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>virginica</li><li>virginica</li><li>virginica</li><li>virginica</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>virginica</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>versicolor</li><li>virginica</li><li>versicolor</li><li>virginica</li><li>virginica</li><li>virginica</li><li>virginica</li><li>versicolor</li><li>virginica</li><li>virginica</li><li>virginica</li><li>virginica</li><li>virginica</li><li>virginica</li><li>versicolor</li><li>versicolor</li><li>virginica</li><li>virginica</li><li>virginica</li><li>virginica</li><li>versicolor</li><li>virginica</li><li>versicolor</li><li>virginica</li><li>virginica</li><li>virginica</li><li>virginica</li><li>versicolor</li><li>versicolor</li><li>virginica</li><li>virginica</li><li>virginica</li><li>virginica</li><li>virginica</li><li>virginica</li><li>versicolor</li><li>virginica</li><li>virginica</li><li>virginica</li><li>versicolor</li><li>virginica</li><li>virginica</li><li>virginica</li><li>versicolor</li><li>virginica</li><li>virginica</li><li>virginica</li><li>versicolor</li><li>virginica</li><li>virginica</li><li>versicolor</li></ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<style>\n",
       "\t.list-inline {list-style: none; margin:0; padding: 0}\n",
       "\t.list-inline>li {display: inline-block}\n",
       "\t.list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "\t</style>\n",
       "\t<ol class=list-inline><li>'setosa'</li><li>'versicolor'</li><li>'virginica'</li></ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item versicolor\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'setosa'\n",
       "\\item 'versicolor'\n",
       "\\item 'virginica'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. setosa\n",
       "2. setosa\n",
       "3. setosa\n",
       "4. setosa\n",
       "5. setosa\n",
       "6. setosa\n",
       "7. setosa\n",
       "8. setosa\n",
       "9. setosa\n",
       "10. setosa\n",
       "11. setosa\n",
       "12. setosa\n",
       "13. setosa\n",
       "14. setosa\n",
       "15. setosa\n",
       "16. setosa\n",
       "17. setosa\n",
       "18. setosa\n",
       "19. setosa\n",
       "20. setosa\n",
       "21. setosa\n",
       "22. setosa\n",
       "23. setosa\n",
       "24. setosa\n",
       "25. setosa\n",
       "26. setosa\n",
       "27. setosa\n",
       "28. setosa\n",
       "29. setosa\n",
       "30. setosa\n",
       "31. setosa\n",
       "32. setosa\n",
       "33. setosa\n",
       "34. setosa\n",
       "35. setosa\n",
       "36. setosa\n",
       "37. setosa\n",
       "38. setosa\n",
       "39. setosa\n",
       "40. setosa\n",
       "41. setosa\n",
       "42. setosa\n",
       "43. setosa\n",
       "44. setosa\n",
       "45. setosa\n",
       "46. setosa\n",
       "47. setosa\n",
       "48. setosa\n",
       "49. setosa\n",
       "50. setosa\n",
       "51. virginica\n",
       "52. virginica\n",
       "53. virginica\n",
       "54. versicolor\n",
       "55. virginica\n",
       "56. versicolor\n",
       "57. virginica\n",
       "58. versicolor\n",
       "59. virginica\n",
       "60. versicolor\n",
       "61. versicolor\n",
       "62. versicolor\n",
       "63. versicolor\n",
       "64. versicolor\n",
       "65. versicolor\n",
       "66. virginica\n",
       "67. versicolor\n",
       "68. versicolor\n",
       "69. versicolor\n",
       "70. versicolor\n",
       "71. versicolor\n",
       "72. versicolor\n",
       "73. versicolor\n",
       "74. versicolor\n",
       "75. virginica\n",
       "76. virginica\n",
       "77. virginica\n",
       "78. virginica\n",
       "79. versicolor\n",
       "80. versicolor\n",
       "81. versicolor\n",
       "82. versicolor\n",
       "83. versicolor\n",
       "84. versicolor\n",
       "85. versicolor\n",
       "86. versicolor\n",
       "87. virginica\n",
       "88. versicolor\n",
       "89. versicolor\n",
       "90. versicolor\n",
       "91. versicolor\n",
       "92. versicolor\n",
       "93. versicolor\n",
       "94. versicolor\n",
       "95. versicolor\n",
       "96. versicolor\n",
       "97. versicolor\n",
       "98. versicolor\n",
       "99. versicolor\n",
       "100. versicolor\n",
       "101. virginica\n",
       "102. versicolor\n",
       "103. virginica\n",
       "104. virginica\n",
       "105. virginica\n",
       "106. virginica\n",
       "107. versicolor\n",
       "108. virginica\n",
       "109. virginica\n",
       "110. virginica\n",
       "111. virginica\n",
       "112. virginica\n",
       "113. virginica\n",
       "114. versicolor\n",
       "115. versicolor\n",
       "116. virginica\n",
       "117. virginica\n",
       "118. virginica\n",
       "119. virginica\n",
       "120. versicolor\n",
       "121. virginica\n",
       "122. versicolor\n",
       "123. virginica\n",
       "124. virginica\n",
       "125. virginica\n",
       "126. virginica\n",
       "127. versicolor\n",
       "128. versicolor\n",
       "129. virginica\n",
       "130. virginica\n",
       "131. virginica\n",
       "132. virginica\n",
       "133. virginica\n",
       "134. virginica\n",
       "135. versicolor\n",
       "136. virginica\n",
       "137. virginica\n",
       "138. virginica\n",
       "139. versicolor\n",
       "140. virginica\n",
       "141. virginica\n",
       "142. virginica\n",
       "143. versicolor\n",
       "144. virginica\n",
       "145. virginica\n",
       "146. virginica\n",
       "147. versicolor\n",
       "148. virginica\n",
       "149. virginica\n",
       "150. versicolor\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'setosa'\n",
       "2. 'versicolor'\n",
       "3. 'virginica'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       "  [7] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [13] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [19] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [25] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [31] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [37] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [43] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [49] setosa     setosa     virginica  virginica  virginica  versicolor\n",
       " [55] virginica  versicolor virginica  versicolor virginica  versicolor\n",
       " [61] versicolor versicolor versicolor versicolor versicolor virginica \n",
       " [67] versicolor versicolor versicolor versicolor versicolor versicolor\n",
       " [73] versicolor versicolor virginica  virginica  virginica  virginica \n",
       " [79] versicolor versicolor versicolor versicolor versicolor versicolor\n",
       " [85] versicolor versicolor virginica  versicolor versicolor versicolor\n",
       " [91] versicolor versicolor versicolor versicolor versicolor versicolor\n",
       " [97] versicolor versicolor versicolor versicolor virginica  versicolor\n",
       "[103] virginica  virginica  virginica  virginica  versicolor virginica \n",
       "[109] virginica  virginica  virginica  virginica  virginica  versicolor\n",
       "[115] versicolor virginica  virginica  virginica  virginica  versicolor\n",
       "[121] virginica  versicolor virginica  virginica  virginica  virginica \n",
       "[127] versicolor versicolor virginica  virginica  virginica  virginica \n",
       "[133] virginica  virginica  versicolor virginica  virginica  virginica \n",
       "[139] versicolor virginica  virginica  virginica  versicolor virginica \n",
       "[145] virginica  virginica  versicolor virginica  virginica  versicolor\n",
       "Levels: setosa versicolor virginica"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod2 = multinom(Species~.,data=dset2)\n",
    "summary(mod2)\n",
    "predict(mod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 150 × 3 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>setosa</th><th scope=col>versicolor</th><th scope=col>virginica</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1.0000000</td><td>6.262518e-13</td><td>9.134601e-14</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.9999999</td><td>1.261362e-07</td><td>1.030832e-08</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1.0000000</td><td>1.164308e-14</td><td>7.051641e-16</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1.0000000</td><td>1.185963e-14</td><td>5.708551e-16</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1.0000000</td><td>1.902668e-16</td><td>2.389135e-17</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>1.0000000</td><td>1.023397e-14</td><td>3.094854e-15</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>1.0000000</td><td>6.109239e-20</td><td>3.315118e-21</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>1.0000000</td><td>6.378996e-13</td><td>7.394781e-14</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>1.0000000</td><td>1.230490e-14</td><td>3.741083e-16</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>1.0000000</td><td>2.178438e-09</td><td>1.852873e-10</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>1.0000000</td><td>3.431101e-11</td><td>9.579101e-12</td></tr>\n",
       "\t<tr><th scope=row>12</th><td>1.0000000</td><td>1.974103e-16</td><td>1.565713e-17</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>1.0000000</td><td>2.218955e-09</td><td>1.499966e-10</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>1.0000000</td><td>3.738453e-18</td><td>9.784721e-20</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>1.0000000</td><td>1.845503e-09</td><td>1.240864e-09</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>1.0000000</td><td>2.888315e-18</td><td>1.884726e-18</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>1.0000000</td><td>1.023397e-14</td><td>3.094854e-15</td></tr>\n",
       "\t<tr><th scope=row>18</th><td>1.0000000</td><td>6.262518e-13</td><td>9.134601e-14</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>0.9999998</td><td>1.088461e-07</td><td>5.588588e-08</td></tr>\n",
       "\t<tr><th scope=row>20</th><td>1.0000000</td><td>3.226004e-18</td><td>5.304722e-19</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>0.9999917</td><td>6.660610e-06</td><td>1.649484e-06</td></tr>\n",
       "\t<tr><th scope=row>22</th><td>1.0000000</td><td>1.867926e-16</td><td>2.951243e-17</td></tr>\n",
       "\t<tr><th scope=row>23</th><td>1.0000000</td><td>1.822207e-23</td><td>1.071061e-24</td></tr>\n",
       "\t<tr><th scope=row>24</th><td>1.0000000</td><td>2.099609e-09</td><td>2.827315e-10</td></tr>\n",
       "\t<tr><th scope=row>25</th><td>1.0000000</td><td>1.974103e-16</td><td>1.565713e-17</td></tr>\n",
       "\t<tr><th scope=row>26</th><td>0.9999921</td><td>7.170141e-06</td><td>7.084206e-07</td></tr>\n",
       "\t<tr><th scope=row>27</th><td>1.0000000</td><td>6.378996e-13</td><td>7.394781e-14</td></tr>\n",
       "\t<tr><th scope=row>28</th><td>1.0000000</td><td>3.559920e-11</td><td>6.277637e-12</td></tr>\n",
       "\t<tr><th scope=row>29</th><td>1.0000000</td><td>2.061270e-09</td><td>3.492517e-10</td></tr>\n",
       "\t<tr><th scope=row>30</th><td>1.0000000</td><td>1.164308e-14</td><td>7.051641e-16</td></tr>\n",
       "\t<tr><th scope=row>...</th><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><th scope=row>121</th><td>4.336169e-26</td><td>0.20248037</td><td>0.7975196</td></tr>\n",
       "\t<tr><th scope=row>122</th><td>9.596078e-10</td><td>0.77832715</td><td>0.2216729</td></tr>\n",
       "\t<tr><th scope=row>123</th><td>1.070736e-47</td><td>0.06127287</td><td>0.9387271</td></tr>\n",
       "\t<tr><th scope=row>124</th><td>5.460822e-24</td><td>0.49188129</td><td>0.5081187</td></tr>\n",
       "\t<tr><th scope=row>125</th><td>1.053137e-20</td><td>0.26283555</td><td>0.7371645</td></tr>\n",
       "\t<tr><th scope=row>126</th><td>1.464673e-31</td><td>0.12562940</td><td>0.8743706</td></tr>\n",
       "\t<tr><th scope=row>127</th><td>1.934130e-20</td><td>0.52930018</td><td>0.4706998</td></tr>\n",
       "\t<tr><th scope=row>128</th><td>3.875900e-15</td><td>0.55655511</td><td>0.4434449</td></tr>\n",
       "\t<tr><th scope=row>129</th><td>4.917148e-24</td><td>0.43482268</td><td>0.5651773</td></tr>\n",
       "\t<tr><th scope=row>130</th><td>4.683178e-35</td><td>0.13467306</td><td>0.8653269</td></tr>\n",
       "\t<tr><th scope=row>131</th><td>3.319372e-42</td><td>0.10341129</td><td>0.8965887</td></tr>\n",
       "\t<tr><th scope=row>132</th><td>6.660968e-34</td><td>0.02907763</td><td>0.9709224</td></tr>\n",
       "\t<tr><th scope=row>133</th><td>4.917148e-24</td><td>0.43482268</td><td>0.5651773</td></tr>\n",
       "\t<tr><th scope=row>134</th><td>3.097769e-22</td><td>0.48189966</td><td>0.5181003</td></tr>\n",
       "\t<tr><th scope=row>135</th><td>3.689893e-22</td><td>0.59556368</td><td>0.4044363</td></tr>\n",
       "\t<tr><th scope=row>136</th><td>3.329779e-44</td><td>0.05683450</td><td>0.9431655</td></tr>\n",
       "\t<tr><th scope=row>137</th><td>1.023708e-11</td><td>0.42258636</td><td>0.5774136</td></tr>\n",
       "\t<tr><th scope=row>138</th><td>8.904582e-19</td><td>0.40562841</td><td>0.5943716</td></tr>\n",
       "\t<tr><th scope=row>139</th><td>2.386147e-13</td><td>0.60275578</td><td>0.3972442</td></tr>\n",
       "\t<tr><th scope=row>140</th><td>7.730258e-28</td><td>0.20900919</td><td>0.7909908</td></tr>\n",
       "\t<tr><th scope=row>141</th><td>3.329710e-24</td><td>0.27860903</td><td>0.7213910</td></tr>\n",
       "\t<tr><th scope=row>142</th><td>7.730258e-28</td><td>0.20900919</td><td>0.7909908</td></tr>\n",
       "\t<tr><th scope=row>143</th><td>4.706903e-15</td><td>0.71430051</td><td>0.2856995</td></tr>\n",
       "\t<tr><th scope=row>144</th><td>2.859006e-24</td><td>0.23485531</td><td>0.7651447</td></tr>\n",
       "\t<tr><th scope=row>145</th><td>1.053137e-20</td><td>0.26283555</td><td>0.7371645</td></tr>\n",
       "\t<tr><th scope=row>146</th><td>5.917789e-26</td><td>0.28671008</td><td>0.7132899</td></tr>\n",
       "\t<tr><th scope=row>147</th><td>1.694947e-27</td><td>0.51185603</td><td>0.4881440</td></tr>\n",
       "\t<tr><th scope=row>148</th><td>2.468272e-22</td><td>0.37007850</td><td>0.6299215</td></tr>\n",
       "\t<tr><th scope=row>149</th><td>6.464441e-10</td><td>0.46943893</td><td>0.5305611</td></tr>\n",
       "\t<tr><th scope=row>150</th><td>1.456404e-11</td><td>0.64719429</td><td>0.3528057</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 150 × 3 of type dbl\n",
       "\\begin{tabular}{r|lll}\n",
       "  & setosa & versicolor & virginica\\\\\n",
       "\\hline\n",
       "\t1 & 1.0000000 & 6.262518e-13 & 9.134601e-14\\\\\n",
       "\t2 & 0.9999999 & 1.261362e-07 & 1.030832e-08\\\\\n",
       "\t3 & 1.0000000 & 1.164308e-14 & 7.051641e-16\\\\\n",
       "\t4 & 1.0000000 & 1.185963e-14 & 5.708551e-16\\\\\n",
       "\t5 & 1.0000000 & 1.902668e-16 & 2.389135e-17\\\\\n",
       "\t6 & 1.0000000 & 1.023397e-14 & 3.094854e-15\\\\\n",
       "\t7 & 1.0000000 & 6.109239e-20 & 3.315118e-21\\\\\n",
       "\t8 & 1.0000000 & 6.378996e-13 & 7.394781e-14\\\\\n",
       "\t9 & 1.0000000 & 1.230490e-14 & 3.741083e-16\\\\\n",
       "\t10 & 1.0000000 & 2.178438e-09 & 1.852873e-10\\\\\n",
       "\t11 & 1.0000000 & 3.431101e-11 & 9.579101e-12\\\\\n",
       "\t12 & 1.0000000 & 1.974103e-16 & 1.565713e-17\\\\\n",
       "\t13 & 1.0000000 & 2.218955e-09 & 1.499966e-10\\\\\n",
       "\t14 & 1.0000000 & 3.738453e-18 & 9.784721e-20\\\\\n",
       "\t15 & 1.0000000 & 1.845503e-09 & 1.240864e-09\\\\\n",
       "\t16 & 1.0000000 & 2.888315e-18 & 1.884726e-18\\\\\n",
       "\t17 & 1.0000000 & 1.023397e-14 & 3.094854e-15\\\\\n",
       "\t18 & 1.0000000 & 6.262518e-13 & 9.134601e-14\\\\\n",
       "\t19 & 0.9999998 & 1.088461e-07 & 5.588588e-08\\\\\n",
       "\t20 & 1.0000000 & 3.226004e-18 & 5.304722e-19\\\\\n",
       "\t21 & 0.9999917 & 6.660610e-06 & 1.649484e-06\\\\\n",
       "\t22 & 1.0000000 & 1.867926e-16 & 2.951243e-17\\\\\n",
       "\t23 & 1.0000000 & 1.822207e-23 & 1.071061e-24\\\\\n",
       "\t24 & 1.0000000 & 2.099609e-09 & 2.827315e-10\\\\\n",
       "\t25 & 1.0000000 & 1.974103e-16 & 1.565713e-17\\\\\n",
       "\t26 & 0.9999921 & 7.170141e-06 & 7.084206e-07\\\\\n",
       "\t27 & 1.0000000 & 6.378996e-13 & 7.394781e-14\\\\\n",
       "\t28 & 1.0000000 & 3.559920e-11 & 6.277637e-12\\\\\n",
       "\t29 & 1.0000000 & 2.061270e-09 & 3.492517e-10\\\\\n",
       "\t30 & 1.0000000 & 1.164308e-14 & 7.051641e-16\\\\\n",
       "\t... & ... & ... & ...\\\\\n",
       "\t121 & 4.336169e-26 & 0.20248037 & 0.7975196\\\\\n",
       "\t122 & 9.596078e-10 & 0.77832715 & 0.2216729\\\\\n",
       "\t123 & 1.070736e-47 & 0.06127287 & 0.9387271\\\\\n",
       "\t124 & 5.460822e-24 & 0.49188129 & 0.5081187\\\\\n",
       "\t125 & 1.053137e-20 & 0.26283555 & 0.7371645\\\\\n",
       "\t126 & 1.464673e-31 & 0.12562940 & 0.8743706\\\\\n",
       "\t127 & 1.934130e-20 & 0.52930018 & 0.4706998\\\\\n",
       "\t128 & 3.875900e-15 & 0.55655511 & 0.4434449\\\\\n",
       "\t129 & 4.917148e-24 & 0.43482268 & 0.5651773\\\\\n",
       "\t130 & 4.683178e-35 & 0.13467306 & 0.8653269\\\\\n",
       "\t131 & 3.319372e-42 & 0.10341129 & 0.8965887\\\\\n",
       "\t132 & 6.660968e-34 & 0.02907763 & 0.9709224\\\\\n",
       "\t133 & 4.917148e-24 & 0.43482268 & 0.5651773\\\\\n",
       "\t134 & 3.097769e-22 & 0.48189966 & 0.5181003\\\\\n",
       "\t135 & 3.689893e-22 & 0.59556368 & 0.4044363\\\\\n",
       "\t136 & 3.329779e-44 & 0.05683450 & 0.9431655\\\\\n",
       "\t137 & 1.023708e-11 & 0.42258636 & 0.5774136\\\\\n",
       "\t138 & 8.904582e-19 & 0.40562841 & 0.5943716\\\\\n",
       "\t139 & 2.386147e-13 & 0.60275578 & 0.3972442\\\\\n",
       "\t140 & 7.730258e-28 & 0.20900919 & 0.7909908\\\\\n",
       "\t141 & 3.329710e-24 & 0.27860903 & 0.7213910\\\\\n",
       "\t142 & 7.730258e-28 & 0.20900919 & 0.7909908\\\\\n",
       "\t143 & 4.706903e-15 & 0.71430051 & 0.2856995\\\\\n",
       "\t144 & 2.859006e-24 & 0.23485531 & 0.7651447\\\\\n",
       "\t145 & 1.053137e-20 & 0.26283555 & 0.7371645\\\\\n",
       "\t146 & 5.917789e-26 & 0.28671008 & 0.7132899\\\\\n",
       "\t147 & 1.694947e-27 & 0.51185603 & 0.4881440\\\\\n",
       "\t148 & 2.468272e-22 & 0.37007850 & 0.6299215\\\\\n",
       "\t149 & 6.464441e-10 & 0.46943893 & 0.5305611\\\\\n",
       "\t150 & 1.456404e-11 & 0.64719429 & 0.3528057\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 150 × 3 of type dbl\n",
       "\n",
       "| <!--/--> | setosa | versicolor | virginica |\n",
       "|---|---|---|---|\n",
       "| 1 | 1.0000000 | 6.262518e-13 | 9.134601e-14 |\n",
       "| 2 | 0.9999999 | 1.261362e-07 | 1.030832e-08 |\n",
       "| 3 | 1.0000000 | 1.164308e-14 | 7.051641e-16 |\n",
       "| 4 | 1.0000000 | 1.185963e-14 | 5.708551e-16 |\n",
       "| 5 | 1.0000000 | 1.902668e-16 | 2.389135e-17 |\n",
       "| 6 | 1.0000000 | 1.023397e-14 | 3.094854e-15 |\n",
       "| 7 | 1.0000000 | 6.109239e-20 | 3.315118e-21 |\n",
       "| 8 | 1.0000000 | 6.378996e-13 | 7.394781e-14 |\n",
       "| 9 | 1.0000000 | 1.230490e-14 | 3.741083e-16 |\n",
       "| 10 | 1.0000000 | 2.178438e-09 | 1.852873e-10 |\n",
       "| 11 | 1.0000000 | 3.431101e-11 | 9.579101e-12 |\n",
       "| 12 | 1.0000000 | 1.974103e-16 | 1.565713e-17 |\n",
       "| 13 | 1.0000000 | 2.218955e-09 | 1.499966e-10 |\n",
       "| 14 | 1.0000000 | 3.738453e-18 | 9.784721e-20 |\n",
       "| 15 | 1.0000000 | 1.845503e-09 | 1.240864e-09 |\n",
       "| 16 | 1.0000000 | 2.888315e-18 | 1.884726e-18 |\n",
       "| 17 | 1.0000000 | 1.023397e-14 | 3.094854e-15 |\n",
       "| 18 | 1.0000000 | 6.262518e-13 | 9.134601e-14 |\n",
       "| 19 | 0.9999998 | 1.088461e-07 | 5.588588e-08 |\n",
       "| 20 | 1.0000000 | 3.226004e-18 | 5.304722e-19 |\n",
       "| 21 | 0.9999917 | 6.660610e-06 | 1.649484e-06 |\n",
       "| 22 | 1.0000000 | 1.867926e-16 | 2.951243e-17 |\n",
       "| 23 | 1.0000000 | 1.822207e-23 | 1.071061e-24 |\n",
       "| 24 | 1.0000000 | 2.099609e-09 | 2.827315e-10 |\n",
       "| 25 | 1.0000000 | 1.974103e-16 | 1.565713e-17 |\n",
       "| 26 | 0.9999921 | 7.170141e-06 | 7.084206e-07 |\n",
       "| 27 | 1.0000000 | 6.378996e-13 | 7.394781e-14 |\n",
       "| 28 | 1.0000000 | 3.559920e-11 | 6.277637e-12 |\n",
       "| 29 | 1.0000000 | 2.061270e-09 | 3.492517e-10 |\n",
       "| 30 | 1.0000000 | 1.164308e-14 | 7.051641e-16 |\n",
       "| ... | ... | ... | ... |\n",
       "| 121 | 4.336169e-26 | 0.20248037 | 0.7975196 |\n",
       "| 122 | 9.596078e-10 | 0.77832715 | 0.2216729 |\n",
       "| 123 | 1.070736e-47 | 0.06127287 | 0.9387271 |\n",
       "| 124 | 5.460822e-24 | 0.49188129 | 0.5081187 |\n",
       "| 125 | 1.053137e-20 | 0.26283555 | 0.7371645 |\n",
       "| 126 | 1.464673e-31 | 0.12562940 | 0.8743706 |\n",
       "| 127 | 1.934130e-20 | 0.52930018 | 0.4706998 |\n",
       "| 128 | 3.875900e-15 | 0.55655511 | 0.4434449 |\n",
       "| 129 | 4.917148e-24 | 0.43482268 | 0.5651773 |\n",
       "| 130 | 4.683178e-35 | 0.13467306 | 0.8653269 |\n",
       "| 131 | 3.319372e-42 | 0.10341129 | 0.8965887 |\n",
       "| 132 | 6.660968e-34 | 0.02907763 | 0.9709224 |\n",
       "| 133 | 4.917148e-24 | 0.43482268 | 0.5651773 |\n",
       "| 134 | 3.097769e-22 | 0.48189966 | 0.5181003 |\n",
       "| 135 | 3.689893e-22 | 0.59556368 | 0.4044363 |\n",
       "| 136 | 3.329779e-44 | 0.05683450 | 0.9431655 |\n",
       "| 137 | 1.023708e-11 | 0.42258636 | 0.5774136 |\n",
       "| 138 | 8.904582e-19 | 0.40562841 | 0.5943716 |\n",
       "| 139 | 2.386147e-13 | 0.60275578 | 0.3972442 |\n",
       "| 140 | 7.730258e-28 | 0.20900919 | 0.7909908 |\n",
       "| 141 | 3.329710e-24 | 0.27860903 | 0.7213910 |\n",
       "| 142 | 7.730258e-28 | 0.20900919 | 0.7909908 |\n",
       "| 143 | 4.706903e-15 | 0.71430051 | 0.2856995 |\n",
       "| 144 | 2.859006e-24 | 0.23485531 | 0.7651447 |\n",
       "| 145 | 1.053137e-20 | 0.26283555 | 0.7371645 |\n",
       "| 146 | 5.917789e-26 | 0.28671008 | 0.7132899 |\n",
       "| 147 | 1.694947e-27 | 0.51185603 | 0.4881440 |\n",
       "| 148 | 2.468272e-22 | 0.37007850 | 0.6299215 |\n",
       "| 149 | 6.464441e-10 | 0.46943893 | 0.5305611 |\n",
       "| 150 | 1.456404e-11 | 0.64719429 | 0.3528057 |\n",
       "\n"
      ],
      "text/plain": [
       "    setosa       versicolor   virginica   \n",
       "1   1.0000000    6.262518e-13 9.134601e-14\n",
       "2   0.9999999    1.261362e-07 1.030832e-08\n",
       "3   1.0000000    1.164308e-14 7.051641e-16\n",
       "4   1.0000000    1.185963e-14 5.708551e-16\n",
       "5   1.0000000    1.902668e-16 2.389135e-17\n",
       "6   1.0000000    1.023397e-14 3.094854e-15\n",
       "7   1.0000000    6.109239e-20 3.315118e-21\n",
       "8   1.0000000    6.378996e-13 7.394781e-14\n",
       "9   1.0000000    1.230490e-14 3.741083e-16\n",
       "10  1.0000000    2.178438e-09 1.852873e-10\n",
       "11  1.0000000    3.431101e-11 9.579101e-12\n",
       "12  1.0000000    1.974103e-16 1.565713e-17\n",
       "13  1.0000000    2.218955e-09 1.499966e-10\n",
       "14  1.0000000    3.738453e-18 9.784721e-20\n",
       "15  1.0000000    1.845503e-09 1.240864e-09\n",
       "16  1.0000000    2.888315e-18 1.884726e-18\n",
       "17  1.0000000    1.023397e-14 3.094854e-15\n",
       "18  1.0000000    6.262518e-13 9.134601e-14\n",
       "19  0.9999998    1.088461e-07 5.588588e-08\n",
       "20  1.0000000    3.226004e-18 5.304722e-19\n",
       "21  0.9999917    6.660610e-06 1.649484e-06\n",
       "22  1.0000000    1.867926e-16 2.951243e-17\n",
       "23  1.0000000    1.822207e-23 1.071061e-24\n",
       "24  1.0000000    2.099609e-09 2.827315e-10\n",
       "25  1.0000000    1.974103e-16 1.565713e-17\n",
       "26  0.9999921    7.170141e-06 7.084206e-07\n",
       "27  1.0000000    6.378996e-13 7.394781e-14\n",
       "28  1.0000000    3.559920e-11 6.277637e-12\n",
       "29  1.0000000    2.061270e-09 3.492517e-10\n",
       "30  1.0000000    1.164308e-14 7.051641e-16\n",
       "... ...          ...          ...         \n",
       "121 4.336169e-26 0.20248037   0.7975196   \n",
       "122 9.596078e-10 0.77832715   0.2216729   \n",
       "123 1.070736e-47 0.06127287   0.9387271   \n",
       "124 5.460822e-24 0.49188129   0.5081187   \n",
       "125 1.053137e-20 0.26283555   0.7371645   \n",
       "126 1.464673e-31 0.12562940   0.8743706   \n",
       "127 1.934130e-20 0.52930018   0.4706998   \n",
       "128 3.875900e-15 0.55655511   0.4434449   \n",
       "129 4.917148e-24 0.43482268   0.5651773   \n",
       "130 4.683178e-35 0.13467306   0.8653269   \n",
       "131 3.319372e-42 0.10341129   0.8965887   \n",
       "132 6.660968e-34 0.02907763   0.9709224   \n",
       "133 4.917148e-24 0.43482268   0.5651773   \n",
       "134 3.097769e-22 0.48189966   0.5181003   \n",
       "135 3.689893e-22 0.59556368   0.4044363   \n",
       "136 3.329779e-44 0.05683450   0.9431655   \n",
       "137 1.023708e-11 0.42258636   0.5774136   \n",
       "138 8.904582e-19 0.40562841   0.5943716   \n",
       "139 2.386147e-13 0.60275578   0.3972442   \n",
       "140 7.730258e-28 0.20900919   0.7909908   \n",
       "141 3.329710e-24 0.27860903   0.7213910   \n",
       "142 7.730258e-28 0.20900919   0.7909908   \n",
       "143 4.706903e-15 0.71430051   0.2856995   \n",
       "144 2.859006e-24 0.23485531   0.7651447   \n",
       "145 1.053137e-20 0.26283555   0.7371645   \n",
       "146 5.917789e-26 0.28671008   0.7132899   \n",
       "147 1.694947e-27 0.51185603   0.4881440   \n",
       "148 2.468272e-22 0.37007850   0.6299215   \n",
       "149 6.464441e-10 0.46943893   0.5305611   \n",
       "150 1.456404e-11 0.64719429   0.3528057   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict(mod2,type=\"probs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>1</dt><dd>1</dd><dt>2</dt><dd>1</dd><dt>3</dt><dd>1</dd><dt>4</dt><dd>1</dd><dt>5</dt><dd>1</dd><dt>6</dt><dd>1</dd><dt>7</dt><dd>1</dd><dt>8</dt><dd>1</dd><dt>9</dt><dd>1</dd><dt>10</dt><dd>1</dd><dt>11</dt><dd>1</dd><dt>12</dt><dd>1</dd><dt>13</dt><dd>1</dd><dt>14</dt><dd>1</dd><dt>15</dt><dd>1</dd><dt>16</dt><dd>1</dd><dt>17</dt><dd>1</dd><dt>18</dt><dd>1</dd><dt>19</dt><dd>1</dd><dt>20</dt><dd>1</dd><dt>21</dt><dd>1</dd><dt>22</dt><dd>1</dd><dt>23</dt><dd>1</dd><dt>24</dt><dd>1</dd><dt>25</dt><dd>1</dd><dt>26</dt><dd>1</dd><dt>27</dt><dd>1</dd><dt>28</dt><dd>1</dd><dt>29</dt><dd>1</dd><dt>30</dt><dd>1</dd><dt>31</dt><dd>1</dd><dt>32</dt><dd>1</dd><dt>33</dt><dd>1</dd><dt>34</dt><dd>1</dd><dt>35</dt><dd>1</dd><dt>36</dt><dd>1</dd><dt>37</dt><dd>1</dd><dt>38</dt><dd>1</dd><dt>39</dt><dd>1</dd><dt>40</dt><dd>1</dd><dt>41</dt><dd>1</dd><dt>42</dt><dd>1</dd><dt>43</dt><dd>1</dd><dt>44</dt><dd>1</dd><dt>45</dt><dd>1</dd><dt>46</dt><dd>1</dd><dt>47</dt><dd>1</dd><dt>48</dt><dd>1</dd><dt>49</dt><dd>1</dd><dt>50</dt><dd>1</dd><dt>51</dt><dd>3</dd><dt>52</dt><dd>3</dd><dt>53</dt><dd>3</dd><dt>54</dt><dd>2</dd><dt>55</dt><dd>3</dd><dt>56</dt><dd>2</dd><dt>57</dt><dd>3</dd><dt>58</dt><dd>2</dd><dt>59</dt><dd>3</dd><dt>60</dt><dd>2</dd><dt>61</dt><dd>2</dd><dt>62</dt><dd>2</dd><dt>63</dt><dd>2</dd><dt>64</dt><dd>2</dd><dt>65</dt><dd>2</dd><dt>66</dt><dd>3</dd><dt>67</dt><dd>2</dd><dt>68</dt><dd>2</dd><dt>69</dt><dd>2</dd><dt>70</dt><dd>2</dd><dt>71</dt><dd>2</dd><dt>72</dt><dd>2</dd><dt>73</dt><dd>2</dd><dt>74</dt><dd>2</dd><dt>75</dt><dd>3</dd><dt>76</dt><dd>3</dd><dt>77</dt><dd>3</dd><dt>78</dt><dd>3</dd><dt>79</dt><dd>2</dd><dt>80</dt><dd>2</dd><dt>81</dt><dd>2</dd><dt>82</dt><dd>2</dd><dt>83</dt><dd>2</dd><dt>84</dt><dd>2</dd><dt>85</dt><dd>2</dd><dt>86</dt><dd>2</dd><dt>87</dt><dd>3</dd><dt>88</dt><dd>2</dd><dt>89</dt><dd>2</dd><dt>90</dt><dd>2</dd><dt>91</dt><dd>2</dd><dt>92</dt><dd>2</dd><dt>93</dt><dd>2</dd><dt>94</dt><dd>2</dd><dt>95</dt><dd>2</dd><dt>96</dt><dd>2</dd><dt>97</dt><dd>2</dd><dt>98</dt><dd>2</dd><dt>99</dt><dd>2</dd><dt>100</dt><dd>2</dd><dt>101</dt><dd>3</dd><dt>102</dt><dd>2</dd><dt>103</dt><dd>3</dd><dt>104</dt><dd>3</dd><dt>105</dt><dd>3</dd><dt>106</dt><dd>3</dd><dt>107</dt><dd>2</dd><dt>108</dt><dd>3</dd><dt>109</dt><dd>3</dd><dt>110</dt><dd>3</dd><dt>111</dt><dd>3</dd><dt>112</dt><dd>3</dd><dt>113</dt><dd>3</dd><dt>114</dt><dd>2</dd><dt>115</dt><dd>2</dd><dt>116</dt><dd>3</dd><dt>117</dt><dd>3</dd><dt>118</dt><dd>3</dd><dt>119</dt><dd>3</dd><dt>120</dt><dd>2</dd><dt>121</dt><dd>3</dd><dt>122</dt><dd>2</dd><dt>123</dt><dd>3</dd><dt>124</dt><dd>3</dd><dt>125</dt><dd>3</dd><dt>126</dt><dd>3</dd><dt>127</dt><dd>2</dd><dt>128</dt><dd>2</dd><dt>129</dt><dd>3</dd><dt>130</dt><dd>3</dd><dt>131</dt><dd>3</dd><dt>132</dt><dd>3</dd><dt>133</dt><dd>3</dd><dt>134</dt><dd>3</dd><dt>135</dt><dd>2</dd><dt>136</dt><dd>3</dd><dt>137</dt><dd>3</dd><dt>138</dt><dd>3</dd><dt>139</dt><dd>2</dd><dt>140</dt><dd>3</dd><dt>141</dt><dd>3</dd><dt>142</dt><dd>3</dd><dt>143</dt><dd>2</dd><dt>144</dt><dd>3</dd><dt>145</dt><dd>3</dd><dt>146</dt><dd>3</dd><dt>147</dt><dd>2</dd><dt>148</dt><dd>3</dd><dt>149</dt><dd>3</dd><dt>150</dt><dd>2</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[1] 1\n",
       "\\item[2] 1\n",
       "\\item[3] 1\n",
       "\\item[4] 1\n",
       "\\item[5] 1\n",
       "\\item[6] 1\n",
       "\\item[7] 1\n",
       "\\item[8] 1\n",
       "\\item[9] 1\n",
       "\\item[10] 1\n",
       "\\item[11] 1\n",
       "\\item[12] 1\n",
       "\\item[13] 1\n",
       "\\item[14] 1\n",
       "\\item[15] 1\n",
       "\\item[16] 1\n",
       "\\item[17] 1\n",
       "\\item[18] 1\n",
       "\\item[19] 1\n",
       "\\item[20] 1\n",
       "\\item[21] 1\n",
       "\\item[22] 1\n",
       "\\item[23] 1\n",
       "\\item[24] 1\n",
       "\\item[25] 1\n",
       "\\item[26] 1\n",
       "\\item[27] 1\n",
       "\\item[28] 1\n",
       "\\item[29] 1\n",
       "\\item[30] 1\n",
       "\\item[31] 1\n",
       "\\item[32] 1\n",
       "\\item[33] 1\n",
       "\\item[34] 1\n",
       "\\item[35] 1\n",
       "\\item[36] 1\n",
       "\\item[37] 1\n",
       "\\item[38] 1\n",
       "\\item[39] 1\n",
       "\\item[40] 1\n",
       "\\item[41] 1\n",
       "\\item[42] 1\n",
       "\\item[43] 1\n",
       "\\item[44] 1\n",
       "\\item[45] 1\n",
       "\\item[46] 1\n",
       "\\item[47] 1\n",
       "\\item[48] 1\n",
       "\\item[49] 1\n",
       "\\item[50] 1\n",
       "\\item[51] 3\n",
       "\\item[52] 3\n",
       "\\item[53] 3\n",
       "\\item[54] 2\n",
       "\\item[55] 3\n",
       "\\item[56] 2\n",
       "\\item[57] 3\n",
       "\\item[58] 2\n",
       "\\item[59] 3\n",
       "\\item[60] 2\n",
       "\\item[61] 2\n",
       "\\item[62] 2\n",
       "\\item[63] 2\n",
       "\\item[64] 2\n",
       "\\item[65] 2\n",
       "\\item[66] 3\n",
       "\\item[67] 2\n",
       "\\item[68] 2\n",
       "\\item[69] 2\n",
       "\\item[70] 2\n",
       "\\item[71] 2\n",
       "\\item[72] 2\n",
       "\\item[73] 2\n",
       "\\item[74] 2\n",
       "\\item[75] 3\n",
       "\\item[76] 3\n",
       "\\item[77] 3\n",
       "\\item[78] 3\n",
       "\\item[79] 2\n",
       "\\item[80] 2\n",
       "\\item[81] 2\n",
       "\\item[82] 2\n",
       "\\item[83] 2\n",
       "\\item[84] 2\n",
       "\\item[85] 2\n",
       "\\item[86] 2\n",
       "\\item[87] 3\n",
       "\\item[88] 2\n",
       "\\item[89] 2\n",
       "\\item[90] 2\n",
       "\\item[91] 2\n",
       "\\item[92] 2\n",
       "\\item[93] 2\n",
       "\\item[94] 2\n",
       "\\item[95] 2\n",
       "\\item[96] 2\n",
       "\\item[97] 2\n",
       "\\item[98] 2\n",
       "\\item[99] 2\n",
       "\\item[100] 2\n",
       "\\item[101] 3\n",
       "\\item[102] 2\n",
       "\\item[103] 3\n",
       "\\item[104] 3\n",
       "\\item[105] 3\n",
       "\\item[106] 3\n",
       "\\item[107] 2\n",
       "\\item[108] 3\n",
       "\\item[109] 3\n",
       "\\item[110] 3\n",
       "\\item[111] 3\n",
       "\\item[112] 3\n",
       "\\item[113] 3\n",
       "\\item[114] 2\n",
       "\\item[115] 2\n",
       "\\item[116] 3\n",
       "\\item[117] 3\n",
       "\\item[118] 3\n",
       "\\item[119] 3\n",
       "\\item[120] 2\n",
       "\\item[121] 3\n",
       "\\item[122] 2\n",
       "\\item[123] 3\n",
       "\\item[124] 3\n",
       "\\item[125] 3\n",
       "\\item[126] 3\n",
       "\\item[127] 2\n",
       "\\item[128] 2\n",
       "\\item[129] 3\n",
       "\\item[130] 3\n",
       "\\item[131] 3\n",
       "\\item[132] 3\n",
       "\\item[133] 3\n",
       "\\item[134] 3\n",
       "\\item[135] 2\n",
       "\\item[136] 3\n",
       "\\item[137] 3\n",
       "\\item[138] 3\n",
       "\\item[139] 2\n",
       "\\item[140] 3\n",
       "\\item[141] 3\n",
       "\\item[142] 3\n",
       "\\item[143] 2\n",
       "\\item[144] 3\n",
       "\\item[145] 3\n",
       "\\item[146] 3\n",
       "\\item[147] 2\n",
       "\\item[148] 3\n",
       "\\item[149] 3\n",
       "\\item[150] 2\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "1\n",
       ":   12\n",
       ":   13\n",
       ":   14\n",
       ":   15\n",
       ":   16\n",
       ":   17\n",
       ":   18\n",
       ":   19\n",
       ":   110\n",
       ":   111\n",
       ":   112\n",
       ":   113\n",
       ":   114\n",
       ":   115\n",
       ":   116\n",
       ":   117\n",
       ":   118\n",
       ":   119\n",
       ":   120\n",
       ":   121\n",
       ":   122\n",
       ":   123\n",
       ":   124\n",
       ":   125\n",
       ":   126\n",
       ":   127\n",
       ":   128\n",
       ":   129\n",
       ":   130\n",
       ":   131\n",
       ":   132\n",
       ":   133\n",
       ":   134\n",
       ":   135\n",
       ":   136\n",
       ":   137\n",
       ":   138\n",
       ":   139\n",
       ":   140\n",
       ":   141\n",
       ":   142\n",
       ":   143\n",
       ":   144\n",
       ":   145\n",
       ":   146\n",
       ":   147\n",
       ":   148\n",
       ":   149\n",
       ":   150\n",
       ":   151\n",
       ":   352\n",
       ":   353\n",
       ":   354\n",
       ":   255\n",
       ":   356\n",
       ":   257\n",
       ":   358\n",
       ":   259\n",
       ":   360\n",
       ":   261\n",
       ":   262\n",
       ":   263\n",
       ":   264\n",
       ":   265\n",
       ":   266\n",
       ":   367\n",
       ":   268\n",
       ":   269\n",
       ":   270\n",
       ":   271\n",
       ":   272\n",
       ":   273\n",
       ":   274\n",
       ":   275\n",
       ":   376\n",
       ":   377\n",
       ":   378\n",
       ":   379\n",
       ":   280\n",
       ":   281\n",
       ":   282\n",
       ":   283\n",
       ":   284\n",
       ":   285\n",
       ":   286\n",
       ":   287\n",
       ":   388\n",
       ":   289\n",
       ":   290\n",
       ":   291\n",
       ":   292\n",
       ":   293\n",
       ":   294\n",
       ":   295\n",
       ":   296\n",
       ":   297\n",
       ":   298\n",
       ":   299\n",
       ":   2100\n",
       ":   2101\n",
       ":   3102\n",
       ":   2103\n",
       ":   3104\n",
       ":   3105\n",
       ":   3106\n",
       ":   3107\n",
       ":   2108\n",
       ":   3109\n",
       ":   3110\n",
       ":   3111\n",
       ":   3112\n",
       ":   3113\n",
       ":   3114\n",
       ":   2115\n",
       ":   2116\n",
       ":   3117\n",
       ":   3118\n",
       ":   3119\n",
       ":   3120\n",
       ":   2121\n",
       ":   3122\n",
       ":   2123\n",
       ":   3124\n",
       ":   3125\n",
       ":   3126\n",
       ":   3127\n",
       ":   2128\n",
       ":   2129\n",
       ":   3130\n",
       ":   3131\n",
       ":   3132\n",
       ":   3133\n",
       ":   3134\n",
       ":   3135\n",
       ":   2136\n",
       ":   3137\n",
       ":   3138\n",
       ":   3139\n",
       ":   2140\n",
       ":   3141\n",
       ":   3142\n",
       ":   3143\n",
       ":   2144\n",
       ":   3145\n",
       ":   3146\n",
       ":   3147\n",
       ":   2148\n",
       ":   3149\n",
       ":   3150\n",
       ":   2\n",
       "\n"
      ],
      "text/plain": [
       "  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20 \n",
       "  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n",
       " 21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40 \n",
       "  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1 \n",
       " 41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60 \n",
       "  1   1   1   1   1   1   1   1   1   1   3   3   3   2   3   2   3   2   3   2 \n",
       " 61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80 \n",
       "  2   2   2   2   2   3   2   2   2   2   2   2   2   2   3   3   3   3   2   2 \n",
       " 81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 \n",
       "  2   2   2   2   2   2   3   2   2   2   2   2   2   2   2   2   2   2   2   2 \n",
       "101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 \n",
       "  3   2   3   3   3   3   2   3   3   3   3   3   3   2   2   3   3   3   3   2 \n",
       "121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 \n",
       "  3   2   3   3   3   3   2   2   3   3   3   3   3   3   2   3   3   3   2   3 \n",
       "141 142 143 144 145 146 147 148 149 150 \n",
       "  3   3   2   3   3   3   2   3   3   2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply(predict(mod2,type=\"probs\"),1,which.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mod = function(mod){\n",
    "    x1r = range(dset2$Sepal.Length)\n",
    "    x2r = range(dset2$Sepal.Width)\n",
    "    x1s = seq(x1r[1],x1r[2],.05)\n",
    "    x2s = seq(x2r[1],x2r[2],.05)\n",
    "    grd = expand.grid(x1s,x2s)\n",
    "    colnames(grd) = c('Sepal.Length','Sepal.Width')\n",
    "    grd_pred = predict(mod,newdata=grd,type='class')\n",
    "    grd_df = cbind(grd,grd_pred)\n",
    "    colnames(grd_df) = c('Sepal.Length','Sepal.Width','Pred')\n",
    "    ggplot(data=grd_df,mapping=aes(x=Sepal.Length,y=Sepal.Width,fill=Pred))+geom_tile()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAQlBMVEUAAAAAujgzMzNNTU1h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\niAwCEpFBQCIyCEhEBv0/Uua3oq5ISvcAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mod(mod2)+geom_point(data=dset2,mapping=aes(x=Sepal.Length,y=Sepal.Width,shape=Species),inherit.aes=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  18 (10 variable)\n",
      "initial  value 164.791843 \n",
      "iter  10 value 59.449065\n",
      "iter  20 value 55.926858\n",
      "iter  30 value 55.239268\n",
      "iter  40 value 55.123997\n",
      "final  value 55.122483 \n",
      "converged\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAQlBMVEUAAAAAujgzMzNNTU1h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\nOtJqvEwAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod3 = multinom(Species~I(Sepal.Width^2)+Sepal.Width*Sepal.Length,data=dset2)\n",
    "plot_mod(mod3)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd,r"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
